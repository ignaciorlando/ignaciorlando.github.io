<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>José Ignacio Orlando on José Ignacio Orlando</title>
    <link>https://ignaciorlando.github.io/</link>
    <description>Recent content in José Ignacio Orlando on José Ignacio Orlando</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 José Ignacio Orlando</copyright>
    <lastBuildDate>Wed, 20 Apr 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Our paper was accepted for IJCARS!</title>
      <link>https://ignaciorlando.github.io/post/news-2019-07-30/</link>
      <pubDate>Tue, 30 Jul 2019 12:00:00 +0000</pubDate>
      
      <guid>https://ignaciorlando.github.io/post/news-2019-07-30/</guid>
      <description>&lt;p&gt;Our paper entitled &amp;ldquo;Improving realism in patient specific Ultrasound simulation using CycleGANs&amp;rdquo; has been accepted for publication in the International Journal of Computer Assisted Radiology and Surgery (IJCARS)!
In this article we present a hybrid approach towards US simulation that combines ray-casting techniques with CycleGANs. The key idea is to use these generative models to alleviate the drawback of current available simulation techniques. In particular, traditional ray-casting based solutions for US simulation usually fail to model complex features such as artifacts or attenuations that are typical from this imaging modality. To overcome this difficulty, we propose to train a CycleGAN using unpaired real US scans and ray-casting based simulations. The model is then applied on simulated images to get more realistic representations. We experimentally evaluated our approach in a user study with a cohort of more than 20 participants, observing that a ResNet based generator is able to significantly improved the appeareance of the images.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;We will need more US experts to further validate our approach&lt;/em&gt;, so if you are willing to help us please contact Santiago Vitale as svitale@conicet.gov.ar.&lt;/p&gt;

&lt;p&gt;This work was part of a collaboration with Santiago Vitale and Ignacio Larrabide, from Pladema / CONICET, and Emmanuel Iarussi, from UTN and also from CONICET.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;headers/cars-pipeline.png&#34; alt=&#34;Brief description of our pipeline&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Multiclass segmentation as multitask learning for drusen segmentation in retinal optical coherence tomography</title>
      <link>https://ignaciorlando.github.io/publication/miccai-drusen/</link>
      <pubDate>Tue, 18 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ignaciorlando.github.io/publication/miccai-drusen/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our paper was accepted for MICCAI!</title>
      <link>https://ignaciorlando.github.io/post/news-2019-06-05/</link>
      <pubDate>Wed, 05 Jun 2019 12:00:00 +0000</pubDate>
      
      <guid>https://ignaciorlando.github.io/post/news-2019-06-05/</guid>
      <description>&lt;p&gt;Our paper entitled &amp;ldquo;Multiclass segmentation as multitask learning for drusen segmentation in retinal optical coherence tomography&amp;rdquo; has been accepted for publication at MICCAI 2019!
Drusen segmentation in OCT is a challenging task. In general, it is posed either as a binary segmentation problem (drusen vs. everything else) or as a layer segmentation problem (by detecting the outer boundary of the RPE and the Bruch&amp;rsquo;s membrane). Each approach has its advantages and disadvantages: binary segmentation might be prone to false positives in areas that are not anatomically plausible, while layer segmentation might fail under the presence of large drusenoid deposits. In this paper we propose to take the best of each world by posing a multiclass segmentation problem in which we target both layers and drusen. Furthermore, instead of training a single, large capacity U-Net model with a multiclass cross entropy loss, we propose to benefit from multitask learning. To this end, we disentangle the multiclass problem as a series of binary segmentation tasks, and we assign to each of them its own decoder, while sharing a single encoder through skip connections. We also analyze if adding connections between the decoders for the layers with the decoder of the drusen segmentation task helps or not. In our experiments we observed better performance when no gradient flow is allowed through these extra connections.&lt;/p&gt;

&lt;p&gt;If you have other problems with &amp;ldquo;sandwiched&amp;rdquo; classes, then maybe this idea can help you to boost your performance :)&lt;/p&gt;

&lt;p&gt;This paper is part of Rhona Asgari&amp;rsquo;s PhD thesis, supervised by Hrvoje Bogunović at OPTIMA.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;headers/miccai2019header.png&#34; alt=&#34;Brief description of our pipeline&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Exploiting Epistemic Uncertainty of Anatomy Segmentation for Anomaly Detection in Retinal OCT</title>
      <link>https://ignaciorlando.github.io/publication/tmi-anomaly/</link>
      <pubDate>Mon, 27 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ignaciorlando.github.io/publication/tmi-anomaly/</guid>
      <description></description>
    </item>
    
    <item>
      <title>U2-Net: A Bayesian U-Net Model with Epistemic Uncertainty Feedback for Photoreceptor Layer Segmentation in Pathological OCT Scans</title>
      <link>https://ignaciorlando.github.io/talk/isbi2019/</link>
      <pubDate>Wed, 10 Apr 2019 15:00:00 +0000</pubDate>
      
      <guid>https://ignaciorlando.github.io/talk/isbi2019/</guid>
      <description>&lt;!--- and
Embed your slides or video here using [shortcodes](https://gcushen.github.io/hugo-academic-demo/post/writing-markdown-latex/). Further details can easily be added using *Markdown* and $\rm \LaTeX$ math code.---&gt;
</description>
    </item>
    
    <item>
      <title>Ultrasound simulation</title>
      <link>https://ignaciorlando.github.io/project/us-simulation/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ignaciorlando.github.io/project/us-simulation/</guid>
      <description>&lt;p&gt;Ultrasound (US) is a fast, low cost imaging technique that is widely use in emergency rooms. As part of this project, we are developing an automated system for US simulation, that allows to produce realistic US scans from segmented CT volumes of real patients.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Two papers accepted for ISBI 2019!</title>
      <link>https://ignaciorlando.github.io/post/news-2018-12-18-isbi/</link>
      <pubDate>Tue, 18 Dec 2018 12:00:00 +0000</pubDate>
      
      <guid>https://ignaciorlando.github.io/post/news-2018-12-18-isbi/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://ignaciorlando.github.io/img/headers/ISBI_2019_banner_web-960.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Excellent news to finish an amazing year of work at &lt;a href=&#34;https://optima.meduniwien.ac.at&#34; target=&#34;_blank&#34;&gt;OPTIMA&lt;/a&gt;! We got two papers accepted for presentation at ISBI 2019 :)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&amp;ldquo;U2-Net: A Bayesian U-Net model with epistemic uncertainty feedback for photoreceptor layer segmentation in pathological OCT scans&amp;rdquo;&lt;/strong&gt; describes a novel U-shaped architecture for photoreceptor layer segmentation in OCT scans. We modified the basic U-Net with LeakyReLUs, batch normalization and dropout to improve the original segmentation performance. Additionally, we used epistemic uncertainty estimation based on Monte Carlo sampling with dropout on test time to provide qualitative feedback about potential errors of the network. We compared our performance with other baseline approaches and we got state of the art performance for this segmentation task! This study was possible thanks to the support of my co-authors: &lt;a href=&#34;https://optima.meduniwien.ac.at/about-us/team/computational-imaging-research/philipp-seeboeck/&#34; target=&#34;_blank&#34;&gt;Phillip Seeböck&lt;/a&gt; and &lt;a href=&#34;https://optima.meduniwien.ac.at/about-us/team/computational-imaging-research/hrvoje-bogunovic/&#34; target=&#34;_blank&#34;&gt;Hrvoje Bogunović&lt;/a&gt; (who helped me with the technical details), &lt;a href=&#34;https://optima.meduniwien.ac.at/about-us/team/clinical-research/sophie-klimscha/&#34; target=&#34;_blank&#34;&gt;Sophie Klimscha&lt;/a&gt; and &lt;a href=&#34;https://optima.meduniwien.ac.at/about-us/team/clinical-research/christoph-grechenig/&#34; target=&#34;_blank&#34;&gt;Christoph Grechenig&lt;/a&gt; (who coordinated the manual annotation procedure for us, thank you guys!), and &lt;a href=&#34;https://optima.meduniwien.ac.at/about-us/team/clinical-research/sebastian-waldstein/&#34; target=&#34;_blank&#34;&gt;Sebastian Waldstein&lt;/a&gt;, &lt;a href=&#34;https://optima.meduniwien.ac.at/about-us/team/clinical-research/bianca-s-gerendas/&#34; target=&#34;_blank&#34;&gt;Bianca S. Gerendas&lt;/a&gt; and &lt;a href=&#34;https://optima.meduniwien.ac.at/about-us/team/clinical-research/ursula-schmidt-erfurth/&#34; target=&#34;_blank&#34;&gt;Ursula Schmidt-Erfurth&lt;/a&gt; (who supervised the study). Thanks a lot!&lt;/p&gt;

&lt;p&gt;The second papers is &lt;strong&gt;&amp;ldquo;Using CycleGANs for effectively reducing image variability across OCT devices and improving retinal fluid segmentation&amp;rdquo;&lt;/strong&gt;, and it is a joint research lead both by &lt;a href=&#34;https://optima.meduniwien.ac.at/about-us/team/computational-imaging-research/philipp-seeboeck/&#34; target=&#34;_blank&#34;&gt;Phillip Seeböck&lt;/a&gt; and &lt;a href=&#34;https://optima.meduniwien.ac.at/about-us/team/computational-imaging-research/david-romo-bucheli/&#34; target=&#34;_blank&#34;&gt;David Romo-Bucheli&lt;/a&gt;. They introduced the idea of using a CycleGAN to reduce the covariate shift between different OCT devices and allows the transfer of existing segmentation models. I&amp;rsquo;ve colaborated with them developing part of the segmentation model. The other co-authors are &lt;a href=&#34;https://optima.meduniwien.ac.at/about-us/team/clinical-research/sebastian-waldstein/&#34; target=&#34;_blank&#34;&gt;Sebastian Waldstein&lt;/a&gt;, &lt;a href=&#34;https://optima.meduniwien.ac.at/about-us/team/computational-imaging-research/hrvoje-bogunovic/&#34; target=&#34;_blank&#34;&gt;Hrvoje Bogunović&lt;/a&gt;, &lt;a href=&#34;https://optima.meduniwien.ac.at/about-us/team/clinical-research/bianca-s-gerendas/&#34; target=&#34;_blank&#34;&gt;Bianca S. Gerendas&lt;/a&gt;, &lt;a href=&#34;https://optima.meduniwien.ac.at/about-us/team/computational-imaging-research/georg-langs/&#34; target=&#34;_blank&#34;&gt;Georg Langs&lt;/a&gt; and &lt;a href=&#34;https://optima.meduniwien.ac.at/about-us/team/clinical-research/ursula-schmidt-erfurth/&#34; target=&#34;_blank&#34;&gt;Ursula Schmidt-Erfurth&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We kindly acknowledge the funding agencies supporting this research, including the Christian Doppler Research Association, the Austrian Federal Ministry for Digital and Economic Affairs and the National Foundation for Research, Technology and Development and the Austrian Science Fund, towards the projects FWF I2714-B31 and WWTF AugUniWien / FA746A0249. We also thank the NVIDIA Corporation for donating Titan X and Titan XP GPUs for our experiments.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Improving realism in patient-specific abdominal Ultrasound simulation using CycleGANs</title>
      <link>https://ignaciorlando.github.io/publication/ijcars-us-simulation/</link>
      <pubDate>Tue, 18 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://ignaciorlando.github.io/publication/ijcars-us-simulation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>U2-Net: A Bayesian U-Net model with epistemic uncertainty feedback for photoreceptor layer segmentation in pathological OCT scans</title>
      <link>https://ignaciorlando.github.io/publication/isbi-uncertainty/</link>
      <pubDate>Tue, 18 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://ignaciorlando.github.io/publication/isbi-uncertainty/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Using CycleGANs for effectively reducing image variability across OCT devices and improving retinal fluid segmentation</title>
      <link>https://ignaciorlando.github.io/publication/isbi-cyclegan/</link>
      <pubDate>Tue, 18 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://ignaciorlando.github.io/publication/isbi-cyclegan/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Machine learning for ophthalmic image analysis</title>
      <link>https://ignaciorlando.github.io/talk/uba2018/</link>
      <pubDate>Fri, 07 Dec 2018 15:00:00 +0000</pubDate>
      
      <guid>https://ignaciorlando.github.io/talk/uba2018/</guid>
      <description>&lt;!--- and
Embed your slides or video here using [shortcodes](https://gcushen.github.io/hugo-academic-demo/post/writing-markdown-latex/). Further details can easily be added using *Markdown* and $\rm \LaTeX$ math code.---&gt;
</description>
    </item>
    
    <item>
      <title>Presentation at UBA</title>
      <link>https://ignaciorlando.github.io/post/news-2018-12-07-uba-presentation/</link>
      <pubDate>Fri, 07 Dec 2018 12:00:00 +0000</pubDate>
      
      <guid>https://ignaciorlando.github.io/post/news-2018-12-07-uba-presentation/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://ignaciorlando.github.io/img/headers/uba-presentation.jpg&#34; alt=&#34;Presentation&#34; /&gt;&lt;/p&gt;

&lt;p&gt;In December 7th I gave a lecture on machine learning for ophthalmic image analysis at the University of Buenos Aires (UBA, Argentina).
This talk was part of the closure event of the &amp;ldquo;Deep Learning for Medical Image Analysis&amp;rdquo; course that &lt;a href=&#34;https://eferrante.github.io/&#34; target=&#34;_blank&#34;&gt;Enzo Ferrante&lt;/a&gt;
taught at the Faculty of Exact Sciences. Thanks Enzo for the invitation!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>REFUGE: Retinal Fundus Glaucoma Challenge</title>
      <link>https://ignaciorlando.github.io/post/news-2018-07-24-refuge/</link>
      <pubDate>Tue, 24 Jul 2018 12:00:00 +0000</pubDate>
      
      <guid>https://ignaciorlando.github.io/post/news-2018-07-24-refuge/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://ignaciorlando.github.io/img/headers/logo_refuge_header.png&#34; alt=&#34;REFUGE&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We kindly invite you to participate in the &lt;a href=&#34;https://refuge.grand-challenge.org/&#34; target=&#34;_blank&#34;&gt;REFUGE challenge&lt;/a&gt; on glaucoma detection in fundus images, as part of the &lt;a href=&#34;https://sites.google.com/site/mwomia2018/&#34; target=&#34;_blank&#34;&gt;Ophthalmic Medical Image Analysis (OMIA) workshop&lt;/a&gt; at &lt;a href=&#34;https://www.miccai2018.org/&#34; target=&#34;_blank&#34;&gt;MICCAI 2018&lt;/a&gt; in Granada (Spain).&lt;/p&gt;

&lt;p&gt;The deadline for submitting your results on the validation set either for glaucoma detection, optic disc/cup segmentation and/or fovea detection is this Friday 28th!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Our paper was accepted for MICCAI 2018!</title>
      <link>https://ignaciorlando.github.io/post/news-2018-05-25-miccai/</link>
      <pubDate>Fri, 25 May 2018 12:00:00 +0000</pubDate>
      
      <guid>https://ignaciorlando.github.io/post/news-2018-05-25-miccai/</guid>
      <description>&lt;p&gt;Our paper entitled &amp;ldquo;Towards a glaucoma risk index based on simulated hemodynamics from fundus images&amp;rdquo; has been accepted for presentation in MICCAI 2018!
In this article we present one of the first attempts to characterize the hemodynamics of the retinal arterioles og glaucomatous patients. To this end, we have used a 0D model for simulating the blood flow in patient specific segmentations of the arteries, and proposed a novel dictionary-learning based strategy for summarizing all the hemodynamic outcomes into a fixed length feature vector. By means of this approach we want to perform clinical studies on large populations to understand the hemodynamics of glaucomatous patients!&lt;/p&gt;

&lt;p&gt;We have good news for you, btw! Jointly with the manuscript, we will also release our code&amp;hellip; and data In particular, we have built LES-AV, a set of 22 fundus photographs taken from the Leuven Eye Study. The images include not only manual annotations of the retinal vessels, but also their classification into arteries and veins.&lt;/p&gt;

&lt;p&gt;This work was part of a collaboration with João Barbosa Breda, Karel van Keer, Matthew B. Blaschko, Pablo J. Blanco and Carlos A. Bulant. This is also part of the work that I made after defending my thesis in Argentina, and before moving to Vienna to join OPTIMA. So, yeah, it is cool to see CONICET again in the MICCAI proceedings :)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://ignaciorlando.github.io/img/miccai2018header.png&#34; alt=&#34;Brief description of our pipeline&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>NVIDIA Hardware Grant</title>
      <link>https://ignaciorlando.github.io/post/news-2018-02-14-nvidia/</link>
      <pubDate>Wed, 14 Feb 2018 12:00:00 +0000</pubDate>
      
      <guid>https://ignaciorlando.github.io/post/news-2018-02-14-nvidia/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://ignaciorlando.github.io/img/titanxp.jpg&#34; alt=&#34;My Titan XP GPU&#34; /&gt;&lt;/p&gt;

&lt;p&gt;My application for the &lt;a href=&#34;https://developer.nvidia.com/academic_gpu_seeding&#34; target=&#34;_blank&#34;&gt;NVIDIA GPU Grant&lt;/a&gt; was accepted! As part of this grant, I will receive a &lt;a href=&#34;https://www.nvidia.com/en-us/titan/titan-xp/&#34; target=&#34;_blank&#34;&gt;NVIDIA Titan XP GPU&lt;/a&gt; to perform my research on deep learning techniques for OCT image analysis. I would really like to thank the NVIDIA Corporation for providing me with this cutting-edge hardware that will certainly help me to improve the efficiency of my methods.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
