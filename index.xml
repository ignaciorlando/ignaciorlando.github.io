<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>José Ignacio Orlando on José Ignacio Orlando</title>
    <link>https://ignaciorlando.github.io/</link>
    <description>Recent content in José Ignacio Orlando on José Ignacio Orlando</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 José Ignacio Orlando</copyright>
    <lastBuildDate>Wed, 20 Apr 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Convocatoria para Estudiantes Avanzados de Ingeniería - Becas INI 2020</title>
      <link>https://ignaciorlando.github.io/post/open-position-2020-ini/</link>
      <pubDate>Wed, 01 Jan 2020 12:00:00 +0000</pubDate>
      
      <guid>https://ignaciorlando.github.io/post/open-position-2020-ini/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;https://ignaciorlando.github.io/img/headers/open-position-2020-ini-header.png&#34; alt=&#34;Flyer&#34; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;resumen&#34;&gt;Resumen&lt;/h2&gt;

&lt;p&gt;Estamos entrevistando estudiantes avanzados de Ingeniería de Sistemas para aplicar a las &lt;a href=&#34;http://secat.unicen.edu.ar/wp-content/uploads/2019/12/Convocatoria_INI_2019v2.pdf&#34; target=&#34;_blank&#34;&gt;Becas de Ingreso a la Investigación (INI) &lt;sup&gt;2020&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2021&lt;/sub&gt; de la Secretaría de Ciencia, Arte y Tecnología (SECAT) de la UNICEN&lt;/a&gt;. Estas becas te aseguran una remuneración de $4500 mensuales que por trabajar 10 horas semanales durante 1 año en un proyecto de investigación específico, con la ayuda de un/a director/a. Los resultados de tu trabajo podés usarlos después como tesis de grado e incluso como prácticas profesionales supervisadas (PPS). Si te interesa, además podemos continuarlo en el marco de un postgrado.&lt;/p&gt;

&lt;p&gt;Las becas son muy competitivas: se dan unas 30 para toda la universidad. La SECAT arma un orden de mérito único con todos los candidatos de toda la universidad, y otorga las becas a los primeros 30. Por este motivo estamos haciendo una preselección de postulantes, para asegurarnos que la persona que se presente tenga muchas más chances de quedar.&lt;/p&gt;

&lt;p&gt;El proyecto en el que trabajarías si saliera la beca se enfoca en desarrollar métodos basados en inteligencia artificial (en particular, redes neuronales convolucionales) para estudiar automáticamente imágenes de la retina (fotografías de fondo de ojo). Queremos poder tener un algoritmo preciso que pueda determinar la existencia de lesiones asociadas a la retinopatía diabética, y que posteriormente pueda utilizarse en una plataforma inteligente de telemedicina oftalmológica que estamos desarrollando con el Hospital El Cruce de Florencio Varela.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Si el proyecto te interesa y te entusiasma hacer investigación en un área como esta, mandame &lt;strong&gt;antes del 1ero de marzo de 2020&lt;/strong&gt; un mail con el asunto &amp;ldquo;INI 2020&amp;rdquo; y tu CV como adjunto a &lt;a href=&#34;mailto:jiorlando@pladema.exa.unicen.edu.ar&#34; target=&#34;_blank&#34;&gt;jiorlando@pladema.exa.unicen.edu.ar&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Una vez que recibamos tu correo, te mandaremos un mail para coordinar una entrevista en PLADEMA, para conocerte un poco más. Más abajo vas a encontrar más detalles sobre la convocatoria, el proyecto y el grupo de investigación.&lt;/p&gt;

&lt;p&gt;Mucha suerte!&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;requisitos-mínimos-preselección-y-fechas&#34;&gt;Requisitos mínimos, preselección y fechas&lt;/h2&gt;

&lt;p&gt;Los requisitos mínimos de la convocatoria podés encontrarlos &lt;a href=&#34;http://secat.unicen.edu.ar/wp-content/uploads/2019/12/Convocatoria_INI_2019v2.pdf&#34; target=&#34;_blank&#34;&gt;en este link&lt;/a&gt;. En resumen, necesitás:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Ser alumno/a avanzado/a de Ingeniería de Sistemas, con más del 50% de las materias aprobadas (con final, incluyendo optativas!)&lt;/li&gt;
&lt;li&gt;Tener un promedio (con aplazos) mayor a al histórico de la carrera (que a junio de 2019 era de 7.15)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Si además tenés algo de experiencia programando en Python o algunas ideas básicas de machine learning o deep learning, es un plus más para nosotros, aunque no es excluyente. Sí nos parece importante que el/la candidato/a sea alguien proactivo/a y que lo/a entusiasme mucho la investigación, y que maneje un poco de inglés (al menos escribiendo).&lt;/p&gt;

&lt;p&gt;Aunque la convocatoria en sí no exige una preselección, analizaremos los perfiles de todos/as los/as candidatos/as que se postulen para asegurarnos que la persona seleccionada tenga muchas chances de quedar.
Si de todas formas no quedás en la preselección, te vamos a tener en cuenta para otras becas que aparezcan, y por supuesto &lt;a href=&#34;podés hacer la tesis con nosotros en cualquiera de los temas que tenemos disponibles en el banco de tesis de la facu&#34; target=&#34;_blank&#34;&gt;https://www.exa.unicen.edu.ar/es/piexa/banco-tesis&lt;/a&gt; (en el combo box &amp;ldquo;A cargo de:&amp;rdquo; seleccioná &amp;ldquo;Dr. José Ignacio Orlando&amp;rdquo;)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;La fecha límite para participar de la preselección es el __1ero de marzo de 2020. Cumplido ese plazo, tenemos tiempo hasta el &lt;strong&gt;25 de marzo de 2020&lt;/strong&gt; para completar toda la documentación y presentarnos a la beca.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Si te presentamos, los resultados de la beca van a estar publicados el 30 de abril de 2020. Para más info, &lt;a href=&#34;hhttp://secat.unicen.edu.ar/wp-content/uploads/2019/12/Convocatoria_INI_2019v2.pdf&#34; target=&#34;_blank&#34;&gt;consultá el detalle de la convocatoria&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;el-proyecto&#34;&gt;El proyecto&lt;/h2&gt;

&lt;p&gt;La retinopatía diabética es una de las consecuencias típicas de la diabetes. Se trata de una enfermedad asintomática que es hoy día una de las principales causas de ceguera evitable a nivel mundial. Las &lt;a href=&#34;https://en.wikipedia.org/wiki/Fundus_photography&#34; target=&#34;_blank&#34;&gt;fotografías de fondo de ojo&lt;/a&gt; son la modalidad de imagen médica más barata para estudiar de manera no-invasiva la retina y detectar los signos más tempranos de la enfermedad para arrancar a tiempo el tratamiento. El Hospital El Cruce de Florencio Varela tiene una red de telemedicina oftalmológica mediante la cual técnicos (no médicos) le toman imágenes en distintos puntos de la provincia de Buenos Aires a pacientes de riesgo. Las imágenes se mandan al hospital, donde los olftalmólogos las analizan y responden con un informe y una recomendación sobre ir o no a consultar un oftalmólogo.&lt;/p&gt;

&lt;p&gt;Este tipo de redes tiene dos problemas: por un lado, necesitás tener muchos médicos cuando el número de imágenes que hay que estudiar empieza a crecer; y por el otro, detectar los signos más tempranos de la retinopatía diabética es un bardo, porque son unos puntitos rojos (microaneurismas) que se confunden mucho con el fondo de la imagen. Es decir, necesitás mucho tiempo por imagen, y por ende muchos médicos cuando el número de imágenes crece.&lt;/p&gt;

&lt;p&gt;La idea central del proyecto es utilizar &lt;a href=&#34;https://en.wikipedia.org/wiki/Convolutional_neural_network&#34; target=&#34;_blank&#34;&gt;redes neuronales convolucionales (convolutional neural networks)&lt;/a&gt; para procesar fotografías de fondo de ojo y &lt;a href=&#34;https://arxiv.org/pdf/1706.03008.pdf&#34; target=&#34;_blank&#34;&gt;determinar automáticamente el riesgo de que el paciente tenga retinopatía diabética&lt;/a&gt;. En particular, queremos poder desarrollar un método lo suficientemente robusto como para asignar un valor de probabilidad a la imagen que indique si el paciente tiene o no retinopatía diabética, y que además brinde información respecto a dónde están las lesiones tenidas en cuneta por la red.&lt;/p&gt;

&lt;p&gt;Google hizo algo parecido en la India, como se ve &lt;a href=&#34;https://youtu.be/V5aZjsWM2wo?t=955&#34; target=&#34;_blank&#34;&gt;en este video tremendo narrado por Iron Man&lt;/a&gt;. Nosotros queremos hacer algo parecido acá, con nuestros propios métodos, 100% argento, para que no haya que comprarle a Google una solución: a fin de cuentas, tenemos todo lo necesario para hacerlo nosotros! Contar con esta herramienta facilitaría mucho el trabajo de los médicos del Hospital El Cruce, y estaríamos resolviendo un problema enorme a nivel local, regional y mundial!&lt;/p&gt;

&lt;p&gt;El proyecto estará supervisado por mí. Durante el transcurso de la beca vamos a utilizar el lenguaje de programación Python y la librería para deep learning Pytorch para desarrollar los métodos propuestos, además de placas gráficas de NVIDIA para correr los experimentos. Además, la iniciativa involucra aprender conceptos muy interesantes de análisis de imagen, visión computacional y machine learning, y embarrarnos un toque con una matemática no muy áspera pero que siempre viene bien aprender :)&lt;/p&gt;

&lt;p&gt;Si querés saber más, mandame un mail a jiorlando@pladema.exa.unicen.edu.ar y nos juntamos a conversar un poco más del tema. También podés encontrar más información sobre temas relacionados en algunas de nuestras publicaciones más recientes:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Orlando, J. I., Breda, J. B., Van Keer, K., Blaschko, M. B., Blanco, P. J., &amp;amp; Bulant, C. A. (2018, September). &lt;a href=&#34;https://arxiv.org/abs/1805.10273&#34; target=&#34;_blank&#34;&gt;Towards a glaucoma risk index based on simulated hemodynamics from fundus images&lt;/a&gt;. In International Conference on Medical Image Computing and Computer-Assisted Intervention (pp. 65-73). Springer, Cham.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Orlando, J. I., Prokofyeva, E., del Fresno, M., &amp;amp; Blaschko, M. B. (2018). &lt;a href=&#34;https://arxiv.org/abs/1706.03008&#34; target=&#34;_blank&#34;&gt;An ensemble deep learning based approach for red lesion detection in fundus images&lt;/a&gt;. Computer methods and programs in biomedicine, 153, 115-127.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Orlando, J. I., Van Keer, K., Barbosa Breda, J., Manterola, H. L., Blaschko, M. B., &amp;amp; Clausse, A. (2017). &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pubmed/29044550&#34; target=&#34;_blank&#34;&gt;Proliferative diabetic retinopathy characterization based on fractal features: Evaluation on a publicly available dataset&lt;/a&gt;. Medical physics, 44(12), 6425-6434.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Orlando, J. I., Prokofyeva, E., &amp;amp; Blaschko, M. B. (2016). &lt;a href=&#34;https://ieeexplore.ieee.org/document/7420682&#34; target=&#34;_blank&#34;&gt;A discriminatively trained fully connected conditional random field model for blood vessel segmentation in fundus images&lt;/a&gt;. IEEE transactions on Biomedical Engineering, 64(1), 16-27.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;pladema&#34;&gt;PLADEMA&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.pladema.net/&#34; target=&#34;_blank&#34;&gt;PLADEMA&lt;/a&gt; es un instituto de investigación de referencia a nivel nacional en materia de análisis de imagen médica. Ubicados en el Campus Universitario de la UNICEN, contamos con numerosos investigadores responsables distribuidos en varios grupos de investigación que se enfocan en diversas áreas, yendo desde la computación gráfica y la simulación hasta el análisis de redes de energía y sistemas de transporte.&lt;/p&gt;

&lt;p&gt;Como parte de este proyecto te incorporarías a &lt;a href=&#34;https://yatiris.github.io&#34; target=&#34;_blank&#34;&gt;Yatiris&lt;/a&gt;, el grupo de análisis de imágenes médicas. Además de un excelente clima de laburo y unos muy buenos cebadores de mates, contamos con acceso a recursos de cómputo suficientes para que puedas trabajar sin inconvenientes y hacer los experimentos necesarios. Contamos además con acceso a bases de datos de imágenes de la retina tanto nuestras como del Hospital El Cruce, y contacto con instituciones de salud en Argentina, Bélgica y Austria como para acceder a datos extra de ser necesario. Como tu potencial director, te puedo ofrecer toda la mano que necesites (incluso codeando! amo codear, jeje) y algunos años de experiencia ya laburando con este tipo de imágenes.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Presentation @ IMAGE AI in Leuven (Belgium)</title>
      <link>https://ignaciorlando.github.io/post/news-2019-12-12/</link>
      <pubDate>Thu, 12 Dec 2019 12:00:00 +0000</pubDate>
      
      <guid>https://ignaciorlando.github.io/post/news-2019-12-12/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://ignaciorlando.github.io/img/headers/presentation_image_ai.jpg&#34; alt=&#34;&amp;quot;What&#39;s next in AI for glaucoma screening? The REFUGE challenge outcomes&amp;quot;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;In December 12th I participated (remotely) as a lecturer at &lt;a href=&#34;https://www.eugs.org/newsletter/newsletter-2019-11/IMAGE_AI.htm&#34; target=&#34;_blank&#34;&gt;IMAGE AI&lt;/a&gt;, an international meeting on artificial intelligence and its application to glaucoma, organized by the European Glaucoma Society in collaboration with researchers from UZ Leuven and VITO. I was invited to present the results of the challenge REFUGE, in whose organization I participated during my postdoc in Austria. &lt;a href=&#34;https://ignaciorlando.github.io/static/pptx/ImageAI2019_alternative.pptx&#34; target=&#34;_blank&#34;&gt;The slides can be found here&lt;/a&gt;. This work is a collaboration between Yanwu Xu, Hrvoje Bogunović, Huazhu Fu, Xiualn Zhang, Fei Li and the REFUGE team.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>What&#39;s next in AI for glaucoma screening? The REFUGE challenge outcomes</title>
      <link>https://ignaciorlando.github.io/talk/imageia2019/</link>
      <pubDate>Sat, 07 Dec 2019 09:30:00 +0000</pubDate>
      
      <guid>https://ignaciorlando.github.io/talk/imageia2019/</guid>
      <description>&lt;!--- and
Embed your slides or video here using [shortcodes](https://gcushen.github.io/hugo-academic-demo/post/writing-markdown-latex/). Further details can easily be added using *Markdown* and $\rm \LaTeX$ math code.---&gt;
</description>
    </item>
    
    <item>
      <title>An amplified-target loss approach for photoreceptor layer segmentation in pathological OCT scans</title>
      <link>https://ignaciorlando.github.io/publication/omia-photoreceptors/</link>
      <pubDate>Tue, 08 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ignaciorlando.github.io/publication/omia-photoreceptors/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Foveal Avascular Zone Segmentation in Clinical Routine Fluorescein Angiographies Using Multitask Learning</title>
      <link>https://ignaciorlando.github.io/publication/omia-faz/</link>
      <pubDate>Tue, 08 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ignaciorlando.github.io/publication/omia-faz/</guid>
      <description></description>
    </item>
    
    <item>
      <title>REFUGE Challenge: A Unified Framework for Evaluating Automated Methods for Glaucoma Assessment from Fundus Photographs</title>
      <link>https://ignaciorlando.github.io/publication/media-refuge/</link>
      <pubDate>Tue, 08 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ignaciorlando.github.io/publication/media-refuge/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Convocatoria para Estudiantes Avanzados de Ingeniería - EVC-CIN 2019</title>
      <link>https://ignaciorlando.github.io/post/open-position-2019-cin/</link>
      <pubDate>Tue, 03 Sep 2019 12:00:00 +0000</pubDate>
      
      <guid>https://ignaciorlando.github.io/post/open-position-2019-cin/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;https://ignaciorlando.github.io/img/headers/open-position-2019-cin-header.png&#34; alt=&#34;Flyer&#34; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;resumen&#34;&gt;Resumen&lt;/h2&gt;

&lt;p&gt;Estamos entrevistando estudiantes avanzados de Ingeniería de Sistemas para aplicar a las &lt;a href=&#34;http://evc.cin.edu.ar/&#34; target=&#34;_blank&#34;&gt;Becas de Estímulo a las Vocaciones Científicas (EVC) del Consejo Universitario Nacional (CIN)&lt;/a&gt;. Estas becas te permiten trabajar 12 horas semanales durante 12 meses en un proyecto de investigación específico, con la ayuda de un/a director/a. Los resultados de tu trabajo podés usarlos después como tesis de grado, o como un punto de apoyo para más adelante hacer un postgrado.&lt;/p&gt;

&lt;p&gt;Dado que estas becas son muy competitivas (se dan unas 1500 para todo el país), estamos haciendo una preselección de candidatos, para asegurarnos que el/la postulante que se presente tenga muchas más chances de quedar.&lt;/p&gt;

&lt;p&gt;El proyecto en el que trabajarías si saliera la beca se enfoca en desarrollar métodos basados en deep learning (aprendizaje profundo) para la caracterización de los vasos sanguíneos de la retina, usando como entrada fotografías de fondo de ojo. Queremos poder tener un algoritmo preciso que pueda segmentar el árbol vascular y clasificar cada uno de sus segmentos en arteria o vena.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Si el proyecto te interesa y te entusiasma hacer investigación en un área como esta, mandame &lt;strong&gt;antes del 1ero de octubre de 2019&lt;/strong&gt; un mail con el asunto &amp;ldquo;EVC-CIN 2019&amp;rdquo; y tu CV como adjunto a &lt;a href=&#34;mailto:jiorlando@conicet.gov.ar&#34; target=&#34;_blank&#34;&gt;jiorlando@conicet.gov.ar&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Más abajo vas a encontrar más detalles sobre la convocatoria, el proyecto y el grupo de investigación.&lt;/p&gt;

&lt;p&gt;Mucha suerte!&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;requisitos-mínimos-preselección-y-fechas&#34;&gt;Requisitos mínimos, preselección y fechas&lt;/h2&gt;

&lt;p&gt;Los requisitos mínimos de la convocatoria podés encontrarlos &lt;a href=&#34;http://evc.cin.edu.ar/attachments/article/11/B-%20REGLAMENTO%20BECAS%20EVC%202019.pdf&#34; target=&#34;_blank&#34;&gt;en este link&lt;/a&gt;. En resumen, necesitás:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;No ser mayor de 30 años al 31 de diciembre de 2019.&lt;/li&gt;
&lt;li&gt;Tener un promedio con aplazos mayor a 6 puntos.&lt;/li&gt;
&lt;li&gt;Tener aprobados con finales más del 50% de las materias de la carrera (tené en cuenta que esto también incluye a las optativas).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Si además tenés algo de experiencia programando en Python o algunas ideas básicas de machine learning o deep learning, es un plus más para nosotros, aunque no es excluyente. Sí nos parece importante que el/la candidato/a sea alguien proactivo/a y que lo/a entusiasme mucho la investigación.&lt;/p&gt;

&lt;p&gt;Aunque la convocatoria en sí no exige una preselección, analizaremos los perfiles de todos/as los/as candidatos/as que se postulen para asegurarnos que la persona seleccionada tenga muchas chances de quedar.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;La fecha límite para participar de la preselección es el &lt;strong&gt;1ero de octubre de 2019&lt;/strong&gt;. Cumplido ese plazo, tenemos tiempo hasta el &lt;strong&gt;4 de octubre de 2019&lt;/strong&gt; para presentar toda la documentación y presentarnos a la beca.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Por fechas de resultados y más, &lt;a href=&#34;http://evc.cin.edu.ar/attachments/article/11/cronograma%20evc%202019.pdf&#34; target=&#34;_blank&#34;&gt;consultá el calendario oficial&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;el-proyecto&#34;&gt;El proyecto&lt;/h2&gt;

&lt;p&gt;Muchas enfermedades tanto visuales como sistémicas se manifiestan a través de alteraciones en la distribución o morfología del árbol vascular de la retina. Las &lt;a href=&#34;https://en.wikipedia.org/wiki/Fundus_photography&#34; target=&#34;_blank&#34;&gt;fotografías de fondo de ojo&lt;/a&gt; son una modalidad de imagen médica que permite estudiar de manera no-invasiva la retina y sus diferentes regiones anatómicas, incluyendo los vasos sanguíneos.&lt;/p&gt;

&lt;p&gt;La idea central del proyecto es utilizar &lt;a href=&#34;https://en.wikipedia.org/wiki/Convolutional_neural_network&#34; target=&#34;_blank&#34;&gt;redes neuronales convolucionales (convolutional neural networks)&lt;/a&gt; para procesar fotografías de fondo de ojo y extraer información de interés sobre la morfología vascular. En particular, queremos poder desarrollar un método lo suficientemente robusto como para simultaneamente &lt;a href=&#34;https://ieeexplore.ieee.org/document/7420682&#34; target=&#34;_blank&#34;&gt;segmentar&lt;/a&gt; y &lt;a href=&#34;https://limo.libis.be/primo-explore/fulldisplay?docid=LIRIAS2811989&amp;amp;context=L&amp;amp;vid=Lirias&amp;amp;search_scope=Lirias&amp;amp;tab=default_tab&amp;amp;lang=en_US&#34; target=&#34;_blank&#34;&gt;clasificar&lt;/a&gt; cada uno de los vasos sanguíneos en arteria o vena. Contar con esta herramienta nos permitirá más adelante estudiar de forma mucho más eficiente grandes volúmenes de imágenes, y poder realizar &lt;a href=&#34;https://arxiv.org/pdf/1805.10273.pdf&#34; target=&#34;_blank&#34;&gt;simulaciones hemodinámicas&lt;/a&gt; para comprender si ciertos parámetros obtenidos de dichas simulaciones se relacionan o no con la presencia de algunas enfermedades.&lt;/p&gt;

&lt;p&gt;El proyecto estará supervisado por mí. Durante el transcurso de la beca vamos a utilizar el lenguaje de programación Python y la librería para deep learning Pytorch para desarrollar los métodos propuestos, además de placas gráficas de NVIDIA para correr los experimentos. Además, la iniciativa involucra aprender conceptos muy interesantes de análisis de imagen, visión computacional y machine learning, y embarrarnos un toque con una matemática no muy áspera :)&lt;/p&gt;

&lt;p&gt;Si querés saber más, mandame un mail a jiorlando@conicet.gov.ar y nos juntamos a conversar un poco más del tema. También podés encontrar más información sobre temas relacionados en algunas de nuestras publicaciones más recientes:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Orlando, J. I., Breda, J. B., Van Keer, K., Blaschko, M. B., Blanco, P. J., &amp;amp; Bulant, C. A. (2018, September). &lt;a href=&#34;https://arxiv.org/abs/1805.10273&#34; target=&#34;_blank&#34;&gt;Towards a glaucoma risk index based on simulated hemodynamics from fundus images&lt;/a&gt;. In International Conference on Medical Image Computing and Computer-Assisted Intervention (pp. 65-73). Springer, Cham.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Orlando, J. I., Prokofyeva, E., del Fresno, M., &amp;amp; Blaschko, M. B. (2018). &lt;a href=&#34;https://arxiv.org/abs/1706.03008&#34; target=&#34;_blank&#34;&gt;An ensemble deep learning based approach for red lesion detection in fundus images&lt;/a&gt;. Computer methods and programs in biomedicine, 153, 115-127.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Orlando, J. I., Van Keer, K., Barbosa Breda, J., Manterola, H. L., Blaschko, M. B., &amp;amp; Clausse, A. (2017). &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pubmed/29044550&#34; target=&#34;_blank&#34;&gt;Proliferative diabetic retinopathy characterization based on fractal features: Evaluation on a publicly available dataset&lt;/a&gt;. Medical physics, 44(12), 6425-6434.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Orlando, J. I., Prokofyeva, E., &amp;amp; Blaschko, M. B. (2016). &lt;a href=&#34;https://ieeexplore.ieee.org/document/7420682&#34; target=&#34;_blank&#34;&gt;A discriminatively trained fully connected conditional random field model for blood vessel segmentation in fundus images&lt;/a&gt;. IEEE transactions on Biomedical Engineering, 64(1), 16-27.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;pladema&#34;&gt;PLADEMA&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.pladema.net/&#34; target=&#34;_blank&#34;&gt;PLADEMA&lt;/a&gt; es un instituto de investigación de referencia a nivel nacional en materia de análisis de imagen médica. Ubicados en el Campus Universitario de la UNICEN, contamos con numerosos investigadores responsables distribuidos en varios grupos de investigación que se enfocan en diversas áreas, yendo desde la computación gráfica y la simulación hasta el análisis de redes de energía y sistemas de transporte.&lt;/p&gt;

&lt;p&gt;Como parte de este proyecto te incorporarías a Yatiris, el grupo de análisis de imágenes médicas. Además de un excelente clima de laburo y unos muy buenos cebadores de mates, contamos con acceso a recursos de cómputo suficientes para que puedas trabajar sin inconvenientes y hacer los experimentos necesarios. Contamos además con acceso a bases de datos públicas de imágenes de la retina, y contacto con instituciones de salud en Argentina, Bélgica y Austria como para acceder a datos extra de ser necesario. Como tu potencial director, te puedo ofrecer toda la mano que necesites (incluso codeando! amo codear, jeje) y algunos años de experiencia ya laburando con este tipo de imágenes.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Moving back to Argentina</title>
      <link>https://ignaciorlando.github.io/post/news-2019-09-01/</link>
      <pubDate>Sun, 01 Sep 2019 12:00:00 +0000</pubDate>
      
      <guid>https://ignaciorlando.github.io/post/news-2019-09-01/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://ignaciorlando.github.io/img/headers/pladema.jpg&#34; alt=&#34;My old/new lab in Argentina&#34; /&gt;&lt;/p&gt;

&lt;p&gt;In September 13th I&amp;rsquo;ll be landing in Argentina to be once again part of PLADEMA, this time as an Assistant Researcher funded by CONICET.
I&amp;rsquo;ll be joining again Yatiris, a group within PLADEMA developing cutting edge technologies for medical image analysis using computer vision, machine learning and
pattern recognition techniques. I&amp;rsquo;ll be responsible of coordinating all the deep learning initiatives, while continuing my own line of research in computer-assisted
ophthalmology.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s hard to say goodbye to OPTIMA and such an amazing group of talents and good people. My time in Vienna was so exciting, full of research
projects from which I learned a lot.
I would like to thank Prof. Schmidt-Erfurth for trusting in me for this position, and also to Bianca Gerendas, Hrvoje Bogunović, Sebastian Waldstein
and Martin Ehler for their continuous support. I would also like to thank all of my colleagues in the lab, specially Philipp, Dominik, Antoine,
Wolf, Rhona, David, Thomas and Sophie. Some of them have turned into really good friends of mine that I will miss a lot being abroad!&lt;/p&gt;

&lt;p&gt;That being said, I&amp;rsquo;m glad to move back to Argentina to give back to the country at least a little bit in proportion to what it did to me since I was born there :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>On Orthogonal Projections for Dimension Reduction and Applications in Augmented Target Loss Functions for Learning Problems</title>
      <link>https://ignaciorlando.github.io/publication/jmiv-orthogonal/</link>
      <pubDate>Fri, 16 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ignaciorlando.github.io/publication/jmiv-orthogonal/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our paper was accepted for IJCARS!</title>
      <link>https://ignaciorlando.github.io/post/news-2019-07-30/</link>
      <pubDate>Tue, 30 Jul 2019 12:00:00 +0000</pubDate>
      
      <guid>https://ignaciorlando.github.io/post/news-2019-07-30/</guid>
      <description>&lt;p&gt;Our paper entitled &amp;ldquo;Improving realism in patient specific Ultrasound simulation using CycleGANs&amp;rdquo; has been accepted for publication in the International Journal of Computer Assisted Radiology and Surgery (IJCARS)!
In this article we present a hybrid approach towards US simulation that combines ray-casting techniques with CycleGANs. The key idea is to use these generative models to alleviate the drawback of current available simulation techniques. In particular, traditional ray-casting based solutions for US simulation usually fail to model complex features such as artifacts or attenuations that are typical from this imaging modality. To overcome this difficulty, we propose to train a CycleGAN using unpaired real US scans and ray-casting based simulations. The model is then applied on simulated images to get more realistic representations. We experimentally evaluated our approach in a user study with a cohort of more than 20 participants, observing that a ResNet based generator is able to significantly improved the appeareance of the images.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;We will need more US experts to further validate our approach&lt;/em&gt;, so if you are willing to help us please contact Santiago Vitale as &lt;a href=&#34;mailto:svitale@conicet.gov.ar&#34; target=&#34;_blank&#34;&gt;svitale@conicet.gov.ar&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This work was part of a collaboration with Santiago Vitale and Ignacio Larrabide, from Pladema / CONICET, and Emmanuel Iarussi, from UTN and also from CONICET.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://ignaciorlando.github.io/img/headers/cars-pipeline.png&#34; alt=&#34;Brief description of our pipeline&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Multiclass segmentation as multitask learning for drusen segmentation in retinal optical coherence tomography</title>
      <link>https://ignaciorlando.github.io/publication/miccai-drusen/</link>
      <pubDate>Tue, 18 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ignaciorlando.github.io/publication/miccai-drusen/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our paper was accepted for MICCAI!</title>
      <link>https://ignaciorlando.github.io/post/news-2019-06-05/</link>
      <pubDate>Wed, 05 Jun 2019 12:00:00 +0000</pubDate>
      
      <guid>https://ignaciorlando.github.io/post/news-2019-06-05/</guid>
      <description>&lt;p&gt;Our paper entitled &amp;ldquo;Multiclass segmentation as multitask learning for drusen segmentation in retinal optical coherence tomography&amp;rdquo; has been accepted for publication at MICCAI 2019!
Drusen segmentation in OCT is a challenging task. In general, it is posed either as a binary segmentation problem (drusen vs. everything else) or as a layer segmentation problem (by detecting the outer boundary of the RPE and the Bruch&amp;rsquo;s membrane). Each approach has its advantages and disadvantages: binary segmentation might be prone to false positives in areas that are not anatomically plausible, while layer segmentation might fail under the presence of large drusenoid deposits. In this paper we propose to take the best of each world by posing a multiclass segmentation problem in which we target both layers and drusen. Furthermore, instead of training a single, large capacity U-Net model with a multiclass cross entropy loss, we propose to benefit from multitask learning. To this end, we disentangle the multiclass problem as a series of binary segmentation tasks, and we assign to each of them its own decoder, while sharing a single encoder through skip connections. We also analyze if adding connections between the decoders for the layers with the decoder of the drusen segmentation task helps or not. In our experiments we observed better performance when no gradient flow is allowed through these extra connections.&lt;/p&gt;

&lt;p&gt;If you have other problems with &amp;ldquo;sandwiched&amp;rdquo; classes, then maybe this idea can help you to boost your performance :)&lt;/p&gt;

&lt;p&gt;This paper is part of Rhona Asgari&amp;rsquo;s PhD thesis, supervised by Hrvoje Bogunović at OPTIMA.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://ignaciorlando.github.io/img/headers/miccai2019header.png&#34; alt=&#34;Brief description of our pipeline&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Exploiting Epistemic Uncertainty of Anatomy Segmentation for Anomaly Detection in Retinal OCT</title>
      <link>https://ignaciorlando.github.io/publication/tmi-anomaly/</link>
      <pubDate>Mon, 27 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ignaciorlando.github.io/publication/tmi-anomaly/</guid>
      <description></description>
    </item>
    
    <item>
      <title>U2-Net: A Bayesian U-Net Model with Epistemic Uncertainty Feedback for Photoreceptor Layer Segmentation in Pathological OCT Scans</title>
      <link>https://ignaciorlando.github.io/talk/isbi2019/</link>
      <pubDate>Wed, 10 Apr 2019 15:00:00 +0000</pubDate>
      
      <guid>https://ignaciorlando.github.io/talk/isbi2019/</guid>
      <description>&lt;!--- and
Embed your slides or video here using [shortcodes](https://gcushen.github.io/hugo-academic-demo/post/writing-markdown-latex/). Further details can easily be added using *Markdown* and $\rm \LaTeX$ math code.---&gt;
</description>
    </item>
    
    <item>
      <title>Ultrasound simulation</title>
      <link>https://ignaciorlando.github.io/project/us-simulation/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://ignaciorlando.github.io/project/us-simulation/</guid>
      <description>&lt;p&gt;Ultrasound (US) is a fast, low cost imaging technique that is widely use in emergency rooms. As part of this project, we are developing an automated system for US simulation, that allows to produce realistic US scans from segmented CT volumes of real patients.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
