<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>José Ignacio Orlando</title>
    <link>https://ignaciorlando.github.io/</link>
      <atom:link href="https://ignaciorlando.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>José Ignacio Orlando</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© 2021 José Ignacio Orlando</copyright><lastBuildDate>Mon, 04 Apr 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://ignaciorlando.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>José Ignacio Orlando</title>
      <link>https://ignaciorlando.github.io/</link>
    </image>
    
    <item>
      <title>Improving foveal avascular zone segmentation in fluorescein angiograms by leveraging manual vessel labels from public color fundus pictures</title>
      <link>https://ignaciorlando.github.io/publication/2022-cycleganfa/</link>
      <pubDate>Mon, 04 Apr 2022 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/publication/2022-cycleganfa/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Posición abierta para Beca de Iniciación Doctoral de Agencia I&#43;D&#43;i</title>
      <link>https://ignaciorlando.github.io/post/2022-open-position-agencia/</link>
      <pubDate>Sun, 20 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/post/2022-open-position-agencia/</guid>
      <description>&lt;h2 id=&#34;resumen&#34;&gt;Resumen&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Fecha de inicio de la beca:&lt;/strong&gt; 1ero de junio de 2022.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Fecha de cierre de la convocatoria:&lt;/strong&gt; 15 de mayo de 2022.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Lugar de trabajo:&lt;/strong&gt; Yatiris, Instituto PLADEMA, Facultad de Ciencias Exactas, UNICEN (Tandil, Argentina).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tema:&lt;/strong&gt; Estrategias para el entrenamiento eficiente de algoritmos de aprendizaje profundo para asistencia al diagnóstico de la retinopatía diabética.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Requisitos:&lt;/strong&gt; Título de Ingeniero/a de Sistemas, de Software o de Informática, o Licenciatura en Informática o Ciencias de la Computación, o Licenciatura en Matemática. Es indispensable contar con conocimientos avanzados de programación. Se valora la experiencia en desarrollo de algoritmos de inteligencia artificial, manejo de idioma inglés y antecedentes de investigación y docencia (por ejemplo, en becas de iniciación a la investigación o pasantías).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Investigador responsable:&lt;/strong&gt; Dr. José Ignacio Orlando (CONICET, UNICEN).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Contacto:&lt;/strong&gt; &lt;a href=&#34;mailto:jiorlando@pladema.exa.unicen.edu.ar&#34;&gt;jiorlando@pladema.exa.unicen.edu.ar&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;la-beca&#34;&gt;La beca&lt;/h2&gt;
&lt;p&gt;Estamos buscando candidatos/as para acceder a una &lt;strong&gt;beca doctoral ya asignada a nuestro laboratorio en el marco de un proyecto PICT startup&lt;/strong&gt; que busca desarrollar algoritmos de deep learning para el reconocimiento automático de patologías oculares a partir de fotografías de fondo de ojo.&lt;/p&gt;
&lt;p&gt;Se trata de una &lt;strong&gt;Beca Doctoral de Nivel Inicial&lt;/strong&gt; otorgada por la Agencia I+D+i para formarte en el marco del Doctorado en Matemática Computacional e Industrial (DMCI, categoría B según la CONEAU) de la Facultad de Ciencias Exactas de la UNICEN.
La beca tiene una duración de 3 años, y corresponde a un estipendio que se te paga mensualmente para que realices el doctorado en nuestro laboratorio. Son de dedicación tiempo completo (40 horas semanales), sólo compatibles con un cargo docente según reglamento. Al término de la beca, podés aplicar a la beca de finalización de doctorado de CONICET para completar los 5 años del doctorado.&lt;/p&gt;
&lt;p&gt;El monto de la beca a marzo de 2022 es de &lt;strong&gt;AR$ 88.021&lt;/strong&gt;, al que puede adicionarse el salario de un cargo docente, en caso de tenerlo. Podés conocer más sobre la beca en el &lt;a href=&#34;https://www.argentina.gob.ar/ciencia/agencia/fondo-para-la-investigacion-cientifica-y-tecnologica-foncyt/requisitos&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;sitio de la Agencia&lt;/a&gt;, o leyendo &lt;a href=&#34;https://www.argentina.gob.ar/sites/default/files/2021/08/reglamento_becas_foncyt_marzo_2019.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;el reglamento de la beca&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;El/la becario/a desarrollaría su tesis doctoral en nuestro Grupo de Análisis de Imágenes Médicas, &lt;a href=&#34;https://yatiris.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yatiris&lt;/a&gt;, parte del &lt;a href=&#34;http://www.pladema.net/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Instituto PLADEMA&lt;/a&gt;, de triple dependencia &lt;a href=&#34;http://exa.unicen.edu.ar/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Facultad de Ciencias Exactas de la UNICEN&lt;/a&gt; (Tandil) / &lt;a href=&#34;https://www.gba.gob.ar/cic/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CIC-PBA&lt;/a&gt; / &lt;a href=&#34;https://www.argentina.gob.ar/cnea&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CNEA&lt;/a&gt;, bajo la dirección del &lt;a href=&#34;https://ignaciorlando.github.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr. José Ignacio Orlando&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;requisitos-mínimos&#34;&gt;Requisitos mínimos&lt;/h2&gt;
&lt;p&gt;Para aplicar al concurso por esta beca, pedimos como requisito mínimo un título de grado en Ingeniería de Sistemas, de Software o de Informática, o Licenciatura en Informática o Ciencias de la Computación.
También pueden aplicar Licenciados/as en Ciencias Matemáticas o afines con conocimientos avanzados de programación.&lt;/p&gt;
&lt;p&gt;Vamos a valorar positivamente:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Conocimientos avanzados de programación, sobre todo en lenguaje Python.&lt;/li&gt;
&lt;li&gt;Conocimientos previos en probabilidades y estadística, machine learning, deep learning e inteligencia artificial.&lt;/li&gt;
&lt;li&gt;Manejo intermedio/avanzado del idioma inglés.&lt;/li&gt;
&lt;li&gt;Motivación y entusiasmo para realizar tareas de investigación de manera interdisciplinaria, colaborando con médicos/as, informáticos/as y matemáticos/as, asistiendo a conferencias internacionales a presentar tus trabajos y escribir artículos científicos.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;el-proyecto&#34;&gt;El proyecto&lt;/h2&gt;
&lt;p&gt;El plan de trabajo contempla introducir nuevos enfoques basados en deep learning y procesamiento de imágenes de la retina para facilitar el diagnóstico de la &lt;a href=&#34;https://www.sightsavers.org/protecting-sight/diabetic-retinopathy/?gclid=CjwKCAiA1L_xBRA2EiwAgcLKAwCOb6NgCEyUj_FeDUR3-R9leebOAiv1WBR2FdZWGPEgY9aGbifDSRoCxdMQAvD_BwE&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;retinopatía diabética&lt;/a&gt;. Nos proponemos por un lado resolver problemáticas asociadas al análisis de imágenes médicas, y por el otro proponer algoritmos novedosos capaces de mejorar los que existen actualmente. En particular nos enfocaremos en brindar soluciones aplicadas que puedan integrarse en &lt;a href=&#34;https://retinar.com.ar/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;retinar&lt;/a&gt;, la plataforma de inteligencia artificial para asistencia al diagnóstico de la retinopatía diabética que estamos desarrollando en el marco del PICT startup en el que se inscribe la beca.&lt;/p&gt;
&lt;p&gt;En particular, queremos desarrollar algoritmos para detectar probabilísticamente la enfermedad, medir el grado de incerteza de los algoritmos, hallar lesiones típicas de la enfermedad, controlar la calidad de las imágenes para descartar estudios que no puedan ser analizados y explorar nuevos biomarcadores a partir de la geometría de los vasos sanguíneos. Google hizo algo parecido en la India, como se ve &lt;a href=&#34;https://youtu.be/V5aZjsWM2wo?t=955&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;en este video tremendo narrado por Iron Man&lt;/a&gt;. Queremos hacer algo parecido acá, con nuestros propios métodos, 100% argento, para que no haya que comprarle a Google una solución: a fin de cuentas, tenemos todo lo necesario para hacerlo nosotros! Colaboraremos para eso con el &lt;a href=&#34;http://www.hospitalelcruce.org/index.php/servicios/81-servicios/3735-oftalmologia&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hospital El Cruce&lt;/a&gt; de Florencio Varela, que tiene su propia &lt;a href=&#34;https://www.hospitalelcruce.org/index.php/noticiasprincipal/4251-programa-de-las-naciones-unidas-elogio-proyecto-de-teleoftalmologia-en-red-implementado-desde-el-hospital-el-cruce&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;red de telemedicina oftalmológica&lt;/a&gt;. En el marco de retinar, buscaremos que tus algoritmos puedan incorporarte rápidamente en la plataforma que estamos desarrollando, para aplicarlos en pacientes reales.&lt;/p&gt;
&lt;p&gt;Durante el doctorado vas a trabajar supervisado/a por mí, que trabajo con este tipo de métodos e imágenes hace ya algún tiempo. Durante el transcurso de la beca vas a formarte en el uso de herramientas para deep learning (Python, Pytorch, Visdom, Tensorboard), aprender banda de conceptos de inteligencia artificial, escribir varios papers y eventualmente hacer alguna que otra pasantía en laboratorios amigos en EE.UU., Bélgica, Austria o Buenos Aires. La iniciativa involucra por supuesto aprender también conceptos de análisis de imagen, visión computacional y machine learning, y embarrarnos un toque con una matemática no muy áspera pero que siempre viene bien aprender :)&lt;/p&gt;
&lt;p&gt;Si querés saber más, mandame un mail a &lt;a href=&#34;mailto:jiorlando@pladema.exa.unicen.edu.ar&#34;&gt;jiorlando@pladema.exa.unicen.edu.ar&lt;/a&gt; y nos juntamos o hacemos una teleconferencia para conversar un poco más del tema. También podés encontrar más información sobre temas relacionados en algunas de &lt;a href=&#34;https://scholar.google.com/citations?hl=es&amp;amp;user=2N3oD28AAAAJ&amp;amp;view_op=list_works&amp;amp;sortby=pubdate&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;nuestras publicaciones más recientes&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;yatiris-y-pladema&#34;&gt;Yatiris y PLADEMA&lt;/h2&gt;
&lt;p&gt;Como parte de este proyecto te incorporarías a &lt;a href=&#34;https://yatiris.github.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yatiris&lt;/a&gt;, el Grupo de Análisis de Imágenes Médicas de &lt;a href=&#34;http://www.pladema.net/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PLADEMA&lt;/a&gt;.
PLADEMA es un instituto de investigación de referencia a nivel nacional en materia de informática aplicada. Ubicados en el hermoso &lt;a href=&#34;https://www.google.com/search?q=campus&amp;#43;unicen&amp;#43;tandil&amp;amp;safe=off&amp;amp;sxsrf=ACYBGNT7AhMgECyRDhzingYKvSE35rJx4g:1580303675614&amp;amp;source=lnms&amp;amp;tbm=isch&amp;amp;sa=X&amp;amp;ved=2ahUKEwjL9eL58ajnAhX3H7kGHWpmB0MQ_AUoAXoECBIQAw&amp;amp;biw=1920&amp;amp;bih=976&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Campus Universitario de la UNICEN&lt;/a&gt;, contamos con numerosos investigadores responsables distribuidos en varios grupos de investigación que se enfocan en diversas áreas, yendo desde la computación gráfica y la simulación hasta el análisis de redes de energía y sistemas de transporte.&lt;/p&gt;
&lt;p&gt;Yatiris funciona en el &lt;a href=&#34;https://www.exa.unicen.edu.ar/es/noticia/pladema-amplio-su-edificio-e-incremento-su-capacidad-trabajo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;nuevo edificio del Instituto PLADEMA&lt;/a&gt;, también ubicado en el Campus Universitario. Además de un excelente clima de laburo, contamos con acceso a recursos de cómputo suficientes para que puedas trabajar sin inconvenientes y hacer los experimentos necesarios. Actualmente tenemos 3 servidores con 6 GPUs NVIDIA capaces de entrenar algoritmos de deep learning, y cada estudiante tiene su propia PC de última generación con una GPU NVIDIA 3060 para trabajar. Contamos además con acceso a bases de datos de imágenes de la retina tanto nuestras como del Hospital El Cruce, y contacto con instituciones de salud en Argentina, Bélgica, Portugal, EE.UU. y Austria como para acceder a datos extras.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;cómo-aplicar&#34;&gt;Cómo aplicar&lt;/h2&gt;
&lt;p&gt;Si te interesa participar del concurso por esta beca, te pedimos que envíes un mail a &lt;a href=&#34;mailto:jiorlando@pladema.exa.unicen.edu.ar&#34;&gt;jiorlando@pladema.exa.unicen.edu.ar&lt;/a&gt; antes del cierre de la convocatoria, con el asunto APLICACIÓN BECA PICT STARTUP, que incluya:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Un CV completo.&lt;/li&gt;
&lt;li&gt;Una nota motivacional tuya indicando por qué te gustaría aplicar a esta beca.&lt;/li&gt;
&lt;li&gt;En lo posible, una carta de referencia de tu director/a de tesis de grado o algún referente con quien hayas trabajado.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Como se indica en el artículo 5 del reglamento de la beca, todos/as los/as candidatos/as serán evaluados por un jurado conformado por 3 investigadores/as de nuestro laboratorio, quienes seleccionarán al mejor candidato o la mejor candidata. Una vez seleccionado/a, presentarás la documentación ante Agencia y vas a poder empezar a trabajar con nosotros.&lt;/p&gt;
&lt;p&gt;Tené en cuenta que no es una beca de CONICET. Es decir, no pasás por un concurso nacional contra muchos postulantes, si no que la cantidad de aplicaciones es mucho más limitada.&lt;/p&gt;
&lt;p&gt;Mucha suerte! Te esperamos!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Linking Function and Structure with ReSenseNet: Predicting Retinal Sensitivity from Optical Coherence Tomography using Deep Learning</title>
      <link>https://ignaciorlando.github.io/publication/2022-resensnet/</link>
      <pubDate>Sat, 05 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/publication/2022-resensnet/</guid>
      <description></description>
    </item>
    
    <item>
      <title>retinar - hacia una plataforma nacional basada en inteligencia artificial para la detección temprana de la retinopatía diabética</title>
      <link>https://ignaciorlando.github.io/talk/retinar-hacia-una-plataforma-nacional-basada-en-inteligencia-artificial-para-la-deteccion-temprana-de-la-retinopatia-diabetica/</link>
      <pubDate>Tue, 16 Nov 2021 12:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/talk/retinar-hacia-una-plataforma-nacional-basada-en-inteligencia-artificial-para-la-deteccion-temprana-de-la-retinopatia-diabetica/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Inteligencia artificial en oftalmología - desarrollos argentinos, oportunidades y desafíos</title>
      <link>https://ignaciorlando.github.io/talk/inteligencia-artificial-en-oftalmologia-desarrollos-argentinos-oportunidades-y-desafios/</link>
      <pubDate>Fri, 29 Oct 2021 09:30:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/talk/inteligencia-artificial-en-oftalmologia-desarrollos-argentinos-oportunidades-y-desafios/</guid>
      <description></description>
    </item>
    
    <item>
      <title>retinar en Ciencia por Cientificxs</title>
      <link>https://ignaciorlando.github.io/post/2021-10-05-cxc3/</link>
      <pubDate>Tue, 05 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/post/2021-10-05-cxc3/</guid>
      <description>&lt;p&gt;El 5 de octubre de este año estuve participando del primer programa de la nueva temporada de Ciencia por Científicos y Científicas, el programa de divulgación de la ciencia de AbraTV, el canal de la UNICEN. Estuve junto a Mercedes Leguía, del Hospital El Cruce, presentando retinar, nuestro proyecto de telemdicina oftalmológica asistida por inteligencia artificial para diagnóstico remoto de la retinopatía diabética. Podés &lt;a href=&#34;https://youtu.be/wB02cmkSezI&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ver el video acá&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Gracias a la gente linda de AbraTV por invitarnos a participar, y por darle difusión a lo que hacemos en la universidad!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>retinar recibe financiamiento del PAC Emprendedores para la Innovación</title>
      <link>https://ignaciorlando.github.io/post/2021-10-01-pac/</link>
      <pubDate>Fri, 01 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/post/2021-10-01-pac/</guid>
      <description>&lt;p&gt;Recibimos financiamiento de parte del Ministerio de Desarrollo Productivo de la Nación en el marco de la convocatoria PAC Emprendedores para la Innovación, enfocado en la creación de PyMEs de base tecnológica para la resolución de problemáticas reales. En nuestro caso, recibiremos un aporte no reembolsable de AR$ 1.173.000, al que responderemos con un monto de contraparte de AR$ 207.000, que utilizaremos para cubrir los costos del desarrollo del prototipo navegable y un primer MVP de la plataforma.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>We&#39;ve received a PIP 2021-2023 grant</title>
      <link>https://ignaciorlando.github.io/post/2021-09-21-pip/</link>
      <pubDate>Tue, 21 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/post/2021-09-21-pip/</guid>
      <description>&lt;p&gt;Our project entitled &amp;ldquo;yatiris++ - AI for clinical applications&amp;rdquo; received funding from CONICET as part of the PIP 2021-2023 grants. The grant corresponds to 3-years funding for a total amount of AR$ 1.200.000, that will be used for supporting our research on AI for neuroimaging, ophthalmology and ultrasound. I&amp;rsquo;m the project leader in this case, and the team is also integrated by Ignacio Larrabide, Alejandro Díaz, Delfina Braggio, Hernán Külsgaard, Camila García, Santiago Vitale and Leandro Rocamora.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>retinar was awarded by NVIDIA</title>
      <link>https://ignaciorlando.github.io/post/2021-06-22-nvidia-applied-research/</link>
      <pubDate>Tue, 22 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/post/2021-06-22-nvidia-applied-research/</guid>
      <description>&lt;p&gt;Our project entitled &amp;ldquo;retinar: assisting remote diabetic retinopathy screening with AI tools&amp;rdquo; was awarded as part of the NVIDIA Applied Research Accelerator Program, from NVIDIA Corporation. We received an initial donation of 500 hours on V100 GPU instances via SaturnCloud, in support of the applied research project in which we intend to implement &lt;a href=&#34;https://retinar.com.ar/en/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;retinar&lt;/a&gt;, an AI based system for detecting diabetic retinopathy from fundus photographs.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>We were awarded with a PICT 2019</title>
      <link>https://ignaciorlando.github.io/post/2021-02-05-pict/</link>
      <pubDate>Fri, 12 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/post/2021-02-05-pict/</guid>
      <description>&lt;p&gt;Our project entitled &amp;ldquo;Characterization of optic nerve head morphology from color fundus pictures using deep learning&amp;rdquo; was granted with a PICT 2019&amp;quot; (CANOA: Caracterización morfológica de la cabeza del nervio óptico en fotografías de fondo de ojo mediante aprendizaje profundo) was accepted as a PICT 2019 Joven Investigador by Agencia I+D+i, the national agency for funding research. This 2 years initiative will be funded with AR$ 475.000.&lt;/p&gt;
&lt;p&gt;Our goal is to develop cutting-edge representation learning approaches to extract novel glaucoma biomarkers from color fundus images. In particular, we will apply autoencoders and multitask learning techniques to extract valuable information describing the morphology of the optic nerve head, the area that is damaged the most by glaucoma.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>retinar en WOW Innovación</title>
      <link>https://ignaciorlando.github.io/post/2021-02-12-wow/</link>
      <pubDate>Fri, 05 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/post/2021-02-12-wow/</guid>
      <description>&lt;p&gt;El 5 de febrero de este año estuve participando del micro de Canal 8 de Mar del Plata WOW Innovación, presentando retinar, nuestro proyecto de telemdicina oftalmológica asistida por inteligencia artificial para diagnóstico remoto de la retinopatía diabética. El programa divulga proyectos de emprendedores de todo el país en diversas disciplinas. Yo estuve comentando el trabajo que hacemos en retinar. Podés &lt;a href=&#34;https://www.youtube.com/watch?v=42YPqXVed-w&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ver el video acá&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Gracias a la gente de WOW por la invitación!!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SketchZooms: Deep multi-view descriptors for matching line drawings</title>
      <link>https://ignaciorlando.github.io/publication/2020-cgf-sketchzooms/</link>
      <pubDate>Sun, 27 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/publication/2020-cgf-sketchzooms/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our project retinar was awarded by Prendete</title>
      <link>https://ignaciorlando.github.io/post/2020-11-20-prendete/</link>
      <pubDate>Fri, 11 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/post/2020-11-20-prendete/</guid>
      <description>&lt;p&gt;retinar won the popular vote in Prendete 2020, the start-up contest organized in Tandil to increase the visibility of innovative initiatives. By winning this prize we were assigned with U$D 10.000 in AWS credits that we will certainly use to deploy our MVP. Thanks you very much to everyone who voted us!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>We were awarded with a JOVIN grant by UNICEN</title>
      <link>https://ignaciorlando.github.io/post/2020-12-11-jovin/</link>
      <pubDate>Fri, 11 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/post/2020-12-11-jovin/</guid>
      <description>&lt;p&gt;Our project entitled &amp;ldquo;Towards a smart platform for remote diabetic retinopathy screening: quality control in fundus photographs using autoencoders&amp;rdquo; (Hacia una plataforma inteligente para el tamizado remoto de la retinopatía diabética: control de calidad de fotografías de fondo de ojo utilizando autocodificadores) was granted with AR$ 50.000 by UNICEN. This grant is part of the initiative Programa de Fortalecimiento a la Ciencia y la Tecnología en Universidad Nacionales from Secretaría de Ciencia, Arte y Tecnología at UNICEN.&lt;/p&gt;
&lt;p&gt;In this project we aim to develop one of the key modules for retinar, our AI-guided telemedicine platform for remote diabetic retinopathy screening. Our goal is to develop AI models for automatically detecting low quality fundus photographs, in order to avoid transmissions of suboptimal scans and to recommend the technicians to reacquire the images before the patient leaves the appointment.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Automated lumen segmentation using multi-frame convolutional neural networks in intravascular ultrasound datasets</title>
      <link>https://ignaciorlando.github.io/publication/2020-ehjdh-ivus/</link>
      <pubDate>Mon, 23 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/publication/2020-ehjdh-ivus/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Machine learning for filtering out false positive grey matter atrophies in single subject voxel based morphometry: A simulation based study</title>
      <link>https://ignaciorlando.github.io/publication/2020-jns-ssvbm/</link>
      <pubDate>Fri, 06 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/publication/2020-jns-ssvbm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>yatiris&#43;&#43;: AI for clinical applications</title>
      <link>https://ignaciorlando.github.io/project/yatiris/</link>
      <pubDate>Sun, 01 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/project/yatiris/</guid>
      <description>&lt;p&gt;Artificial intelligence is a cutting edge area in computer science that has recently been incorporated to medical imaging problems. However, most of the technological solutions associated to this field are usually developed in developed countries and subsequently bought by ours.&lt;/p&gt;
&lt;p&gt;This project aims to develop novel AI techniques to solve medical imaging and biomedical engineering problems. To this end, we will introduce novel methods for image analysis based on machine/deep learning that will improve and/or complement current existing developments from Yatiris, the medical imaging group from PLADEMA Institute (UNICEN, Tandil, Argentina). Our purpose is to develop solution for key applications in medical personel training, clinical research, diagnostic, treatment and following of ophthalmological, vascular and neurological diseases. By the end of this project, we aim to count with sufficiently mature tools to be transfered to different medical institutions from Argentina.&lt;/p&gt;
&lt;p&gt;PIs: Ignacio Larrabide, PhD and José Ignacio Orlando, PhD (CONICET / PLADEMA-UNICEN)&lt;/p&gt;
&lt;p&gt;Collaborators:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Alejandro Díaz, MD - CONICET / Facultad de Ciencias de la Salud, UNICEN, Olavarría, PBA, Argentina.&lt;/li&gt;
&lt;li&gt;Delfina Braggio, Eng - CONICET / PLADEMA-UNICEN, Tandil, PBA, Argentina.&lt;/li&gt;
&lt;li&gt;Hernán Külsgaard, Eng - CONICET / PLADEMA-UNICEN, Tandil, PBA, Argentina.&lt;/li&gt;
&lt;li&gt;Camila García, Eng - CONICET / PLADEMA-UNICEN, Tandil, PBA, Argentina.&lt;/li&gt;
&lt;li&gt;Santiago Vitale, Eng - CONICET / PLADEMA-UNICEN, Tandil, PBA, Argentina&lt;/li&gt;
&lt;li&gt;Leandro Rocamora, MSc - PLADEMA-UNICEN, Tandil, PBA, Argentina&lt;/li&gt;
&lt;li&gt;Mercedes Leguía, MD - Hospital de Alta Complejidad El Cruce Dr. Néstor Carlos Kirchner, Florencio Varela, PBA, Argentina.&lt;/li&gt;
&lt;li&gt;Alejandro Koch, MD - Hospital de Alta Complejidad El Cruce Dr. Néstor Carlos Kirchner, Florencio Varela, PBA, Argentina.&lt;/li&gt;
&lt;li&gt;Ezequiel Rosendi, MD - Hospital de Alta Complejidad El Cruce Dr. Néstor Carlos Kirchner, Florencio Varela, PBA, Argentina.&lt;/li&gt;
&lt;li&gt;Oliver Gamondi, MD - Fisiología, Facultad de Ciencias de la Salud, UNICEN, Olavarría, PBA, Argentina.&lt;/li&gt;
&lt;li&gt;Mariana Bendersky, MD PhD - CONICET / ENyS / UBA / Hospital de Alta Complejidad El Cruce Dr. Néstor Carlos Kirchner, Florencio Varela, PBA, Argentina.&lt;/li&gt;
&lt;li&gt;Mariana Vallejo Azar, MD - CONICET / ENyS / UBA / Hospital de Alta Complejidad El Cruce Dr. Néstor Carlos Kirchner, Florencio Varela, PBA, Argentina.&lt;/li&gt;
&lt;li&gt;Juan Pablo Princich, MD PhD - ENyS / Hospital de Alta Complejidad El Cruce Dr. Néstor Carlos Kirchner, Florencio Varela, PBA, Argentina.&lt;/li&gt;
&lt;li&gt;Paula González, PhD - CONICET / ENyS / Hospital de Alta Complejidad El Cruce Dr. Néstor Carlos Kirchner, Florencio Varela, PBA, Argentina.&lt;/li&gt;
&lt;li&gt;Silvia Kochen, MD PhD - CONICET / ENyS / Hospital de Alta Complejidad El Cruce Dr. Néstor Carlos Kirchner, Florencio Varela, PBA, Argentina.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Supported by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PIP 2021-2023. yatiris++: inteligencia artificial para aplicaciones clínicas basadas en imágenes médicas.&lt;/li&gt;
&lt;li&gt;Kaggle Open Data Research Grant.&lt;/li&gt;
&lt;li&gt;NVIDIA Hardware Grant.&lt;/li&gt;
&lt;li&gt;PICT 2016-0116. HI-MED: Computational tools applied to medical image quantification, simulation and treatment planning (Herramientas Informáticas aplicadas a la cuantificación de imagen, simulación y planicación del tratamiento en MEDicina.)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>AGE Challenge: Angle Closure Glaucoma Evaluation in Anterior Segment Optical Coherence Tomography</title>
      <link>https://ignaciorlando.github.io/publication/2020-media-age/</link>
      <pubDate>Fri, 31 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/publication/2020-media-age/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Automated Quantification of Photoreceptor alteration in macular disease using Optical Coherence Tomography and Deep Learning</title>
      <link>https://ignaciorlando.github.io/publication/2020-sr-photoreceptors/</link>
      <pubDate>Fri, 27 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/publication/2020-sr-photoreceptors/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Reducing image variability across OCT devices with unsupervised unpaired learning for improved segmentation of retina</title>
      <link>https://ignaciorlando.github.io/publication/2020-boe-cyclegan/</link>
      <pubDate>Fri, 27 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/publication/2020-boe-cyclegan/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Convocatoria para Postulantes a Becas Doctorales CONICET 2020 y CIC-PBA 2020</title>
      <link>https://ignaciorlando.github.io/post/2020-open-position-conicet/</link>
      <pubDate>Tue, 28 Jan 2020 12:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/post/2020-open-position-conicet/</guid>
      <description>&lt;h2 id=&#34;resumen&#34;&gt;Resumen&lt;/h2&gt;
&lt;p&gt;Estamos buscando aspirantes para postular a las becas doctorales de CONICET y/o CIC-PBA 2020, para incorporarse a RetinAR, un proyecto enfocado en el desarrollo de métodos basados en deep learning para analizar automáticamente imágenes de la retina y ayudar a los médicos a obtener mejores diagnósticos de retinopatía diabética.&lt;/p&gt;
&lt;p&gt;Buscamos graduados/as o alumnos/as avanzados/as de carreras informáticas como Ingeniería de Sistemas, de Software o de Informática, o Licenciatura en Informática o Ciencias de la Computación, y afines.&lt;/p&gt;
&lt;p&gt;La idea es que hagas tu tesis doctoral con nosotros, en nuestro Grupo de Análisis de Imágenes Médicas, &lt;a href=&#34;https://yatiris.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yatiris&lt;/a&gt;, parte del &lt;a href=&#34;http://www.pladema.net/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Instituto PLADEMA&lt;/a&gt;, de triple dependencia &lt;a href=&#34;http://exa.unicen.edu.ar/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Facultad de Ciencias Exactas de la UNICEN&lt;/a&gt; (Tandil) / &lt;a href=&#34;https://www.gba.gob.ar/cic/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CIC-PBA&lt;/a&gt; / &lt;a href=&#34;https://www.argentina.gob.ar/cnea&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CNEA&lt;/a&gt;. El postgrado es el &lt;a href=&#34;https://www.exa.unicen.edu.ar/es/estudios/posgrado/doctorado-matematica-computacional-e-industrial&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Doctorado en Matemática Computacional e Industrial&lt;/a&gt; de la Facultad de Ciencias Exactas de la UNICEN (Categoría B CONEAU), que brinda el marco ideal para desarrollar una tesis en inteligencia artificial.&lt;/p&gt;
&lt;p&gt;Como postulante, aplicarías al llamado de &lt;a href=&#34;https://convocatorias.conicet.gov.ar/becas/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;becas doctorales de CONICET 2020&lt;/a&gt; (&lt;strong&gt;deadline 7 de agosto de 2020&lt;/strong&gt;) y, en simultáneo, al de &lt;a href=&#34;https://www.gba.gob.ar/cic/becas_doctorales&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CIC-PBA 2020&lt;/a&gt; (&lt;strong&gt;deadline 30 de agosto de 2020&lt;/strong&gt;). Ambas becas son incompatibles entre sí, por lo que si salen ambas tendrías que optar por una de las dos. Sin embargo, la idea es presentarte en las dos convocatorias para que tengas más chances :)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Si el proyecto te interesa y te entusiasma hacer investigación en un área como esta, mandame un mail con el asunto &amp;ldquo;Postulación Becas Doctorales CONICET 2020 - [Apellido]&amp;rdquo;, tu CV (con detalle de materias cursadas, calificaciones sin omitir aplazos, experiencia en investigación, asistencia a congresos, publicaciones y demás) y una breve carta de motivación (2 páginas) como adjunto a &lt;a href=&#34;mailto:jiorlando@pladema.exa.unicen.edu.ar&#34;&gt;jiorlando@pladema.exa.unicen.edu.ar&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Una vez que recibamos tu correo, te mandaremos un mail para coordinar una entrevista por teleconferencia, para conocerte un poco más. Más abajo vas a encontrar más detalles sobre la convocatoria, el proyecto y el grupo de investigación.&lt;/p&gt;
&lt;p&gt;Mucha suerte!&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;requisitos-mínimos&#34;&gt;Requisitos mínimos&lt;/h2&gt;
&lt;p&gt;Dado que las becas doctorales son muy competitivas, te pedimos que tengas en cuenta los siguientes requisitos mínimos antes de aplicar. No son nuestros, los imponen las propias convocatorias, y de no cumplirlos puede que sea más difícil que la consigas:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ser graduadx de una de las carreras mencionadas previamente o estudiante avanzado con menos de 4 o 5 finales adeudados a la fecha (o con perspectivas de poder rendirlos de aquí al 31 de marzo del 2021).&lt;/li&gt;
&lt;li&gt;Tener un promedio (con aplazos) mayor a al histórico de tu carrera (podés averiguarlo en Secretaría Académica o de Alumnos de tu facultad)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Nosotros en particular te pedimos que tengas:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Conocimientos avanzados de programación y probabilidades y estadística.&lt;/li&gt;
&lt;li&gt;Mucho interés en trabajar temas de machine learning&lt;/li&gt;
&lt;li&gt;Motivación y entusiasmo para realizar tareas de investigación de manera interdisciplinaria, colaborando con médicos/as, informáticos/as y matemáticos/as, asistiendo a conferencias internacionales a presentar tus trabajos y escribir artículos científicos.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Si tenés algo de experiencia programando en Python y/o utilizando modelos de machine learning o deep learning, es un re plus para nosotros, aunque no es excluyente. Sí nos parece importante que seas proactivo/a y que te entusiasme mucho investigar. También tener un buen nivel de inglés suma, ya que contemplamos colaborar con otros grupos del exterior durante los últimos años del doctorado.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;el-proyecto&#34;&gt;El proyecto&lt;/h2&gt;
&lt;p&gt;El plan de trabajo contempla introducir nuevos enfoques basados en deep learning y procesamiento de imágenes de la retina para facilitar el diagnóstico de la &lt;a href=&#34;https://www.sightsavers.org/protecting-sight/diabetic-retinopathy/?gclid=CjwKCAiA1L_xBRA2EiwAgcLKAwCOb6NgCEyUj_FeDUR3-R9leebOAiv1WBR2FdZWGPEgY9aGbifDSRoCxdMQAvD_BwE&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;retinopatía diabética&lt;/a&gt;. Nos proponemos por un lado resolver problemáticas asociadas al análisis de imágenes médicas, y por el otro proponer algoritmos novedosos capaces de mejorar los que existen actualmente. En particular nos enfocaremos en brindar soluciones aplicadas que puedan integrarse en RetinAR, una plataforma de inteligencia artificial que incorporaremos a la red de telemedicina oftalmológica del Hospital El Cruce de Florencio Varela (Buenos Aires, Argentina), para mejorar su eficiencia y poder llevar un mejor diagnóstico temprano de la retinopatía diabética a un mayor número de pacientes. Trabajaremos mayoritariamente con &lt;a href=&#34;https://en.wikipedia.org/wiki/Fundus_photography&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;fotografías de fondo de ojo&lt;/a&gt; y &lt;a href=&#34;https://en.wikipedia.org/wiki/Optical_coherence_tomography&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;tomografías de coherencia óptica&lt;/a&gt;, que son las imágenes que más se usan en estas enfermedades.&lt;/p&gt;
&lt;p&gt;En particular, queremos desarrollar algoritmos para detectar probabilísticamente la enfermedad, medir el grado de incerteza de los algoritmos, hallar lesiones típicas de la enfermedad, controlar la calidad de las imágenes para descartar estudios que no puedan ser analizados y explorar nuevos biomarcadores a partir de la geometría de los vasos sanguíneos. Google hizo algo parecido en la India, como se ve &lt;a href=&#34;https://youtu.be/V5aZjsWM2wo?t=955&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;en este video tremendo narrado por Iron Man&lt;/a&gt;. Queremos hacer algo parecido acá, con nuestros propios métodos, 100% argento, para que no haya que comprarle a Google una solución: a fin de cuentas, tenemos todo lo necesario para hacerlo nosotros! Colaboraremos para eso con el &lt;a href=&#34;http://www.hospitalelcruce.org/index.php/servicios/81-servicios/3735-oftalmologia&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hospital El Cruce&lt;/a&gt; de Florencio Varela, que tiene su propia &lt;a href=&#34;https://www.hospitalelcruce.org/index.php/noticiasprincipal/4251-programa-de-las-naciones-unidas-elogio-proyecto-de-teleoftalmologia-en-red-implementado-desde-el-hospital-el-cruce&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;red de telemedicina oftalmológica&lt;/a&gt;. En el marco de RetinAR, un proyecto conjunto que estamos iniciando con ellos, buscaremos que los algoritmos que desarrolles durante tu tesis se puedan incorporar en esa red, para facilitar el diagnóstico de la enfermedad.&lt;/p&gt;
&lt;p&gt;Durante el doctorado vas a trabajar supervisado/a por mí, que trabajo con este tipo de métodos e imágenes hace ya algún tiempo. Durante el transcurso de la beca vas a formarte en el uso de herramientas para deep learning (Python, Pytorch, Visdom, Tensorboard), aprender banda de conceptos de inteligencia artificial, escribir varios papers y hacer alguna que otra pasantía en laboratorios amigos en USA, Bélgica, Austria o Buenos Aires. La iniciativa involucra por supuesto aprender también conceptos de análisis de imagen, visión computacional y machine learning, y embarrarnos un toque con una matemática no muy áspera pero que siempre viene bien aprender :)&lt;/p&gt;
&lt;p&gt;Si querés saber más, mandame un mail a &lt;a href=&#34;mailto:jiorlando@pladema.exa.unicen.edu.ar&#34;&gt;jiorlando@pladema.exa.unicen.edu.ar&lt;/a&gt; y nos juntamos o hacemos una teleconferencia para conversar un poco más del tema. También podés encontrar más información sobre temas relacionados en algunas de nuestras publicaciones más recientes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Orlando, J. I., Fu, H., Breda, J. B., van Keer, K., Bathula, D. R., Diaz-Pinto, A., &amp;hellip; &amp;amp; Lee, J. (2020). &lt;a href=&#34;https://arxiv.org/pdf/1910.03667.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;REFUGE Challenge: A unified framework for evaluating automated methods for glaucoma assessment from fundus photographs&lt;/a&gt;. Medical image analysis, 59, 101570.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Orlando, J. I., Seeböck, P., Bogunović, H., Klimscha, S., Grechenig, C., Waldstein, S., &amp;hellip; &amp;amp; Schmidt-Erfurth, U. (2019, April). &lt;a href=&#34;https://arxiv.org/pdf/1901.07929.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;U2-net: A Bayesian U-Net model with epistemic uncertainty feedback for photoreceptor layer segmentation in pathological OCT scans&lt;/a&gt;. In 2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019) (pp. 1441-1445). IEEE.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Orlando, J. I., Breda, J. B., Van Keer, K., Blaschko, M. B., Blanco, P. J., &amp;amp; Bulant, C. A. (2018, September). &lt;a href=&#34;https://arxiv.org/abs/1805.10273&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Towards a glaucoma risk index based on simulated hemodynamics from fundus images&lt;/a&gt;. In International Conference on Medical Image Computing and Computer-Assisted Intervention (pp. 65-73). Springer, Cham.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Orlando, J. I., Prokofyeva, E., del Fresno, M., &amp;amp; Blaschko, M. B. (2018). &lt;a href=&#34;https://arxiv.org/abs/1706.03008&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;An ensemble deep learning based approach for red lesion detection in fundus images&lt;/a&gt;. Computer methods and programs in biomedicine, 153, 115-127.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Orlando, J. I., Van Keer, K., Barbosa Breda, J., Manterola, H. L., Blaschko, M. B., &amp;amp; Clausse, A. (2017). &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pubmed/29044550&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Proliferative diabetic retinopathy characterization based on fractal features: Evaluation on a publicly available dataset&lt;/a&gt;. Medical physics, 44(12), 6425-6434.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;las-becas&#34;&gt;Las becas&lt;/h3&gt;
&lt;p&gt;Las becas doctorales de CONICET se otorgan por 5 años, y corresponden a un estipendio que se te paga mensualmente para que realices un doctorado en una universidad nacional. Recientemente, [las becas han recibido un incremento significativo en número y monto, &lt;a href=&#34;https://www.lanacion.com.ar/sociedad/el-gobierno-aumento-45000-pesos-becas-investigacion-nid2324647&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ascendiendo a junio de 2020 a $45.430 mensuales&lt;/a&gt;. Así mismo, son compatibles con un cargo de docencia simple en una universidad, lo que adiciona alrededor de $7000 o más, dependiendo de tu antigüedad como docente. Además, incluye obra social (&lt;a href=&#34;https://www.accordsalud.com.ar/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Accord Salud&lt;/a&gt;, el plan privado de Unión Personal) y 30 días de vacaciones al año. Un requisito esencial para empezar a percibirla es que estés graduado/a al 31 de marzo de 2021. De no haber conseguido graduarte en ese plazo, la beca se pierde, con lo cual tené en mente eso a la hora de presentarte.&lt;/p&gt;
&lt;p&gt;Las becas de formación doctoral de la CIC-PBA se otorgan por 12 meses, pero pueden prorrogarse a solicitud del o la becario/a hasta 3 períodos consecutivos de 12 meses c/u. Como requisito, además de estar graduado/a, te piden ser menor a 30 años de edad. A medida que las becas se prorrogan, el monto se incrementa, aunque por lo general permanece por debajo del monto de las becas de CONICET. El monto inicial asciende hoy día a 29.000 durante los primeros 2 años, y sube a 35.000 en los últimos años. Podés encontrar &lt;a href=&#34;http://www.cic.gba.gob.ar/wp-content/uploads/2017/01/Legislacion-Reglamento-Becas-Doctorales-873-16-1.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;más información sobre estas becas acá&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;De ser seleccionado/a para la beca de CONICET, comenzarías tus actividades el 1ero de Abril de 2021, con financiamiento por 5 años. Si fueses seleccionado para la de CIC-PBA, la idea es solicitar 2 prórrogas, y cuando comiences el 3er año de doctorado presentarte a las becas de finalización de doctorado de CONICET (que son equivalentes a las doctorales de CONICET pero que se otorgan por 2 años). De esa forma, te aseguraríamos 5 años de formación, en las mejores condiciones posibles!&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;yatiris-y-pladema&#34;&gt;Yatiris y PLADEMA&lt;/h2&gt;
&lt;p&gt;Como parte de este proyecto te incorporarías a &lt;a href=&#34;https://yatiris.github.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yatiris&lt;/a&gt;, el Grupo de Análisis de Imágenes Médicas de &lt;a href=&#34;http://www.pladema.net/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PLADEMA&lt;/a&gt;.
PLADEMA es un instituto de investigación de referencia a nivel nacional en materia de informática aplicada. Ubicados en el hermoso &lt;a href=&#34;https://www.google.com/search?q=campus&amp;#43;unicen&amp;#43;tandil&amp;amp;safe=off&amp;amp;sxsrf=ACYBGNT7AhMgECyRDhzingYKvSE35rJx4g:1580303675614&amp;amp;source=lnms&amp;amp;tbm=isch&amp;amp;sa=X&amp;amp;ved=2ahUKEwjL9eL58ajnAhX3H7kGHWpmB0MQ_AUoAXoECBIQAw&amp;amp;biw=1920&amp;amp;bih=976&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Campus Universitario de la UNICEN&lt;/a&gt;, contamos con numerosos investigadores responsables distribuidos en varios grupos de investigación que se enfocan en diversas áreas, yendo desde la computación gráfica y la simulación hasta el análisis de redes de energía y sistemas de transporte.&lt;/p&gt;
&lt;p&gt;Yatiris funciona en el &lt;a href=&#34;https://www.exa.unicen.edu.ar/es/noticia/pladema-amplio-su-edificio-e-incremento-su-capacidad-trabajo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;nuevo edificio del Instituto PLADEMA&lt;/a&gt;, también ubicado en el Campus Universitario. Además de un excelente clima de laburo y unos muy buenos cebadores de mates, contamos con acceso a recursos de cómputo suficientes para que puedas trabajar sin inconvenientes y hacer los experimentos necesarios. Actualmente tenemos 2 servidores con 4 GPUs NVIDIA capaces de entrenar algoritmos de deep learning, y estamos cerrando en los próximos meses la compra de un nuevo servidor con 2 nuevas placas gráficas. Contamos además con acceso a bases de datos de imágenes de la retina tanto nuestras como del Hospital El Cruce, y contacto con instituciones de salud en Argentina, Bélgica, Portugal, USA y Austria como para acceder a datos extras.&lt;/p&gt;
&lt;p&gt;Te esperamos!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>We were granted with a Kaggle Open Data Research Grant</title>
      <link>https://ignaciorlando.github.io/post/2020-01-22-kaggle/</link>
      <pubDate>Wed, 22 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/post/2020-01-22-kaggle/</guid>
      <description>&lt;p&gt;We are proud to announce that we were awarded with a &lt;a href=&#34;https://www.kaggle.com/open-data-research-grant-2020-awardees#project-title-12&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kaggle Open Data Research Grant&lt;/a&gt; for Santiago Vitale&amp;rsquo;s PhD project on GANs for ultrasound simulation. This grant comprises U$D 2.000 and are awarded to AI initiatives that will ultimately release both code and data. In this case, it was assigned to our project on ultrasound simulation using a combination of ray-casting techniques and GANs. This is part of Santiago&amp;rsquo;s PhD thesis, supervised by Ignacio Larrabide and in which I&amp;rsquo;m collaborating mostly for the AI part. The other team members are Emmanual Iarussi (CONICET / UTN Regional CABA) and Alejandro Díaz (CONICET / UNICEN).&lt;/p&gt;
&lt;p&gt;This grant comes in the right moment, as we were seeking to improve our computational resources by buying new NVIDIA GPUs. Thanks Google Kaggle for supporting our research!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Convocatoria para Estudiantes Avanzados de Ingeniería - Becas INI 2020</title>
      <link>https://ignaciorlando.github.io/post/2020-open-position-ini/</link>
      <pubDate>Wed, 01 Jan 2020 12:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/post/2020-open-position-ini/</guid>
      <description>&lt;h2 id=&#34;resumen&#34;&gt;Resumen&lt;/h2&gt;
&lt;p&gt;Estamos entrevistando estudiantes avanzados de Ingeniería de Sistemas para aplicar a las &lt;a href=&#34;http://secat.unicen.edu.ar/wp-content/uploads/2019/12/Convocatoria_INI_2019v2.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Becas de Ingreso a la Investigación (INI) 2020/2021 de la Secretaría de Ciencia, Arte y Tecnología (SECAT) de la UNICEN&lt;/a&gt;. Estas becas te aseguran una remuneración de $4500 mensuales que por trabajar 10 horas semanales durante 1 año en un proyecto de investigación específico, con la ayuda de un/a director/a. Los resultados de tu trabajo podés usarlos después como tesis de grado e incluso como prácticas profesionales supervisadas (PPS). Si te interesa, además podemos continuarlo en el marco de un postgrado.&lt;/p&gt;
&lt;p&gt;Las becas son muy competitivas: se dan unas 30 para toda la universidad. La SECAT arma un orden de mérito único con todos los candidatos de toda la universidad, y otorga las becas a los primeros 30. Por este motivo estamos haciendo una preselección de postulantes, para asegurarnos que la persona que se presente tenga muchas más chances de quedar.&lt;/p&gt;
&lt;p&gt;El proyecto en el que trabajarías si saliera la beca se enfoca en desarrollar métodos basados en inteligencia artificial (en particular, redes neuronales convolucionales) para estudiar automáticamente imágenes de la retina (fotografías de fondo de ojo). Queremos poder tener un algoritmo preciso que pueda determinar la existencia de lesiones asociadas a la retinopatía diabética, y que posteriormente pueda utilizarse en una plataforma inteligente de telemedicina oftalmológica que estamos desarrollando con el Hospital El Cruce de Florencio Varela.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Si el proyecto te interesa y te entusiasma hacer investigación en un área como esta, mandame &lt;strong&gt;antes del 1ero de marzo de 2020&lt;/strong&gt; un mail con el asunto &amp;ldquo;INI 2020&amp;rdquo; y tu CV como adjunto a &lt;a href=&#34;mailto:jiorlando@pladema.exa.unicen.edu.ar&#34;&gt;jiorlando@pladema.exa.unicen.edu.ar&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Una vez que recibamos tu correo, te mandaremos un mail para coordinar una entrevista en PLADEMA, para conocerte un poco más. Más abajo vas a encontrar más detalles sobre la convocatoria, el proyecto y el grupo de investigación.&lt;/p&gt;
&lt;p&gt;Mucha suerte!&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;requisitos-mínimos-preselección-y-fechas&#34;&gt;Requisitos mínimos, preselección y fechas&lt;/h2&gt;
&lt;p&gt;Los requisitos mínimos de la convocatoria podés encontrarlos &lt;a href=&#34;http://secat.unicen.edu.ar/wp-content/uploads/2019/12/Convocatoria_INI_2019v2.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;en este link&lt;/a&gt;. En resumen, necesitás:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ser alumno/a avanzado/a de Ingeniería de Sistemas, con más del 50% de las materias aprobadas (con final, incluyendo optativas!)&lt;/li&gt;
&lt;li&gt;Tener un promedio (con aplazos) mayor a al histórico de la carrera (que a junio de 2019 era de 7.15)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Si además tenés algo de experiencia programando en Python o algunas ideas básicas de machine learning o deep learning, es un plus más para nosotros, aunque no es excluyente. Sí nos parece importante que el/la candidato/a sea alguien proactivo/a y que lo/a entusiasme mucho la investigación, y que maneje un poco de inglés (al menos escribiendo).&lt;/p&gt;
&lt;p&gt;Aunque la convocatoria en sí no exige una preselección, analizaremos los perfiles de todos/as los/as candidatos/as que se postulen para asegurarnos que la persona seleccionada tenga muchas chances de quedar.
Si de todas formas no quedás en la preselección, te vamos a tener en cuenta para otras becas que aparezcan, y por supuesto [https://www.exa.unicen.edu.ar/es/piexa/banco-tesis](podés hacer la tesis con nosotros en cualquiera de los temas que tenemos disponibles en el banco de tesis de la facu) (en el combo box &amp;ldquo;A cargo de:&amp;rdquo; seleccioná &amp;ldquo;Dr. José Ignacio Orlando&amp;rdquo;)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;La fecha límite para participar de la preselección es el __1ero de marzo de 2020. Cumplido ese plazo, tenemos tiempo hasta el &lt;strong&gt;25 de marzo de 2020&lt;/strong&gt; para completar toda la documentación y presentarnos a la beca.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Si te presentamos, los resultados de la beca van a estar publicados el 30 de abril de 2020. Para más info, &lt;a href=&#34;hhttp://secat.unicen.edu.ar/wp-content/uploads/2019/12/Convocatoria_INI_2019v2.pdf&#34;&gt;consultá el detalle de la convocatoria&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;el-proyecto&#34;&gt;El proyecto&lt;/h2&gt;
&lt;p&gt;La retinopatía diabética es una de las consecuencias típicas de la diabetes. Se trata de una enfermedad asintomática que es hoy día una de las principales causas de ceguera evitable a nivel mundial. Las &lt;a href=&#34;https://en.wikipedia.org/wiki/Fundus_photography&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;fotografías de fondo de ojo&lt;/a&gt; son la modalidad de imagen médica más barata para estudiar de manera no-invasiva la retina y detectar los signos más tempranos de la enfermedad para arrancar a tiempo el tratamiento. El Hospital El Cruce de Florencio Varela tiene una red de telemedicina oftalmológica mediante la cual técnicos (no médicos) le toman imágenes en distintos puntos de la provincia de Buenos Aires a pacientes de riesgo. Las imágenes se mandan al hospital, donde los olftalmólogos las analizan y responden con un informe y una recomendación sobre ir o no a consultar un oftalmólogo.&lt;/p&gt;
&lt;p&gt;Este tipo de redes tiene dos problemas: por un lado, necesitás tener muchos médicos cuando el número de imágenes que hay que estudiar empieza a crecer; y por el otro, detectar los signos más tempranos de la retinopatía diabética es un bardo, porque son unos puntitos rojos (microaneurismas) que se confunden mucho con el fondo de la imagen. Es decir, necesitás mucho tiempo por imagen, y por ende muchos médicos cuando el número de imágenes crece.&lt;/p&gt;
&lt;p&gt;La idea central del proyecto es utilizar &lt;a href=&#34;https://en.wikipedia.org/wiki/Convolutional_neural_network&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;redes neuronales convolucionales (convolutional neural networks)&lt;/a&gt; para procesar fotografías de fondo de ojo y &lt;a href=&#34;https://arxiv.org/pdf/1706.03008.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;determinar automáticamente el riesgo de que el paciente tenga retinopatía diabética&lt;/a&gt;. En particular, queremos poder desarrollar un método lo suficientemente robusto como para asignar un valor de probabilidad a la imagen que indique si el paciente tiene o no retinopatía diabética, y que además brinde información respecto a dónde están las lesiones tenidas en cuneta por la red.&lt;/p&gt;
&lt;p&gt;Google hizo algo parecido en la India, como se ve &lt;a href=&#34;https://youtu.be/V5aZjsWM2wo?t=955&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;en este video tremendo narrado por Iron Man&lt;/a&gt;. Nosotros queremos hacer algo parecido acá, con nuestros propios métodos, 100% argento, para que no haya que comprarle a Google una solución: a fin de cuentas, tenemos todo lo necesario para hacerlo nosotros! Contar con esta herramienta facilitaría mucho el trabajo de los médicos del Hospital El Cruce, y estaríamos resolviendo un problema enorme a nivel local, regional y mundial!&lt;/p&gt;
&lt;p&gt;El proyecto estará supervisado por mí. Durante el transcurso de la beca vamos a utilizar el lenguaje de programación Python y la librería para deep learning Pytorch para desarrollar los métodos propuestos, además de placas gráficas de NVIDIA para correr los experimentos. Además, la iniciativa involucra aprender conceptos muy interesantes de análisis de imagen, visión computacional y machine learning, y embarrarnos un toque con una matemática no muy áspera pero que siempre viene bien aprender :)&lt;/p&gt;
&lt;p&gt;Si querés saber más, mandame un mail a &lt;a href=&#34;mailto:jiorlando@pladema.exa.unicen.edu.ar&#34;&gt;jiorlando@pladema.exa.unicen.edu.ar&lt;/a&gt; y nos juntamos a conversar un poco más del tema. También podés encontrar más información sobre temas relacionados en algunas de nuestras publicaciones más recientes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Orlando, J. I., Breda, J. B., Van Keer, K., Blaschko, M. B., Blanco, P. J., &amp;amp; Bulant, C. A. (2018, September). &lt;a href=&#34;https://arxiv.org/abs/1805.10273&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Towards a glaucoma risk index based on simulated hemodynamics from fundus images&lt;/a&gt;. In International Conference on Medical Image Computing and Computer-Assisted Intervention (pp. 65-73). Springer, Cham.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Orlando, J. I., Prokofyeva, E., del Fresno, M., &amp;amp; Blaschko, M. B. (2018). &lt;a href=&#34;https://arxiv.org/abs/1706.03008&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;An ensemble deep learning based approach for red lesion detection in fundus images&lt;/a&gt;. Computer methods and programs in biomedicine, 153, 115-127.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Orlando, J. I., Van Keer, K., Barbosa Breda, J., Manterola, H. L., Blaschko, M. B., &amp;amp; Clausse, A. (2017). &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pubmed/29044550&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Proliferative diabetic retinopathy characterization based on fractal features: Evaluation on a publicly available dataset&lt;/a&gt;. Medical physics, 44(12), 6425-6434.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Orlando, J. I., Prokofyeva, E., &amp;amp; Blaschko, M. B. (2016). &lt;a href=&#34;https://ieeexplore.ieee.org/document/7420682&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;A discriminatively trained fully connected conditional random field model for blood vessel segmentation in fundus images&lt;/a&gt;. IEEE transactions on Biomedical Engineering, 64(1), 16-27.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;pladema&#34;&gt;PLADEMA&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://www.pladema.net/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PLADEMA&lt;/a&gt; es un instituto de investigación de referencia a nivel nacional en materia de análisis de imagen médica. Ubicados en el Campus Universitario de la UNICEN, contamos con numerosos investigadores responsables distribuidos en varios grupos de investigación que se enfocan en diversas áreas, yendo desde la computación gráfica y la simulación hasta el análisis de redes de energía y sistemas de transporte.&lt;/p&gt;
&lt;p&gt;Como parte de este proyecto te incorporarías a &lt;a href=&#34;https://yatiris.github.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yatiris&lt;/a&gt;, el grupo de análisis de imágenes médicas. Además de un excelente clima de laburo y unos muy buenos cebadores de mates, contamos con acceso a recursos de cómputo suficientes para que puedas trabajar sin inconvenientes y hacer los experimentos necesarios. Contamos además con acceso a bases de datos de imágenes de la retina tanto nuestras como del Hospital El Cruce, y contacto con instituciones de salud en Argentina, Bélgica y Austria como para acceder a datos extra de ser necesario. Como tu potencial director, te puedo ofrecer toda la mano que necesites (incluso codeando! amo codear, jeje) y algunos años de experiencia ya laburando con este tipo de imágenes.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Presentation at IMAGE AI in Leuven, Belgium</title>
      <link>https://ignaciorlando.github.io/post/2019-12-12-imageai/</link>
      <pubDate>Thu, 12 Dec 2019 12:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/post/2019-12-12-imageai/</guid>
      <description>&lt;p&gt;In December 12th I participated (remotely) as a lecturer at &lt;a href=&#34;https://www.eugs.org/newsletter/newsletter-2019-11/IMAGE_AI.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;IMAGE AI&lt;/a&gt;, an international meeting on artificial intelligence and its application to glaucoma, organized by the European Glaucoma Society in collaboration with researchers from UZ Leuven and VITO. I was invited to present the results of the challenge REFUGE, in whose organization I participated during my postdoc in Austria. &lt;a href=&#34;https://ignaciorlando.github.io/static/pptx/ImageAI2019_alternative.pptx&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The slides can be found here&lt;/a&gt;. This work is a collaboration between Yanwu Xu, Hrvoje Bogunović, Huazhu Fu, Xiualn Zhang, Fei Li and the REFUGE team.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>What&#39;s next in AI for glaucoma screening? The REFUGE challenge outcomes</title>
      <link>https://ignaciorlando.github.io/talk/whats-next-in-ai-for-glaucoma-screening-the-refuge-challenge-outcomes/</link>
      <pubDate>Sat, 07 Dec 2019 09:30:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/talk/whats-next-in-ai-for-glaucoma-screening-the-refuge-challenge-outcomes/</guid>
      <description></description>
    </item>
    
    <item>
      <title>retinar: AI for diabetic retinopathy screening</title>
      <link>https://ignaciorlando.github.io/project/retinar/</link>
      <pubDate>Fri, 01 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/project/retinar/</guid>
      <description>&lt;p&gt;Diabetic retinopathy is the leading cause of preventable blindness in working age populations. Color fundus photography is currently used for telemedicine campaigns in which diabetic patients are remotely screened once an year through this imaging modality. The images are acquired by trained technicians, who transfer them to a study center in which retina experts analyzed them to determine the diagnostic. When the amount of patients increases, so does the number of images to analyze. As a consequence, these platforms suffer from scalability issues, which seriously affect their accuracy and efficiency.&lt;/p&gt;
&lt;p&gt;In this project we aim to develop an AI-assisted platform to allow for efficient screening of diabetic retinopathy. Our system will use deep learning techniques to ensure capturing high quality photographs in the acquisitions centers and to provide early diagnostics to the patients. It will also feature lesion detections modules that will be used by the ophthalmologists to produce more accurate reports.&lt;/p&gt;
&lt;p&gt;PI: José Ignacio Orlando, PhD&lt;/p&gt;
&lt;p&gt;Collaborators:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mercedes Leguía, MD - Hospital de Alta Complejidad El Cruce Dr. Néstor Carlos Kirchner, Florencio Varela, PBA, Argentina.&lt;/li&gt;
&lt;li&gt;Alejandro Koch, MD - Hospital de Alta Complejidad El Cruce Dr. Néstor Carlos Kirchner, Florencio Varela, PBA, Argentina.&lt;/li&gt;
&lt;li&gt;Ignacio Larrabide, PhD - CONICET / PLADEMA-UNICEN.&lt;/li&gt;
&lt;li&gt;Ezequiel Rosendi, MD - Hospital de Alta Complejidad El Cruce Dr. Néstor Carlos Kirchner, Florencio Varela, PBA, Argentina.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Supported by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PICT startup 2021-00023 (&amp;ldquo;retinar: artificial intelligence for computer-assisted diagnosis of diabetic retinopathy&amp;rdquo;). FONCyT. Agencia Nacional de Promoción de la Investigación, el Desarrollo Tecnológico y la Innovación (Agencia I+D+i).&lt;/li&gt;
&lt;li&gt;PAC Emprendedores para la Innovación. Ministerio de Desarrollo Productivo de la Nación.&lt;/li&gt;
&lt;li&gt;NVIDIA Applied Research Accelerator Program (500 hours on V100 GPU instances via SaturnCloud).&lt;/li&gt;
&lt;li&gt;JOVIN 2020/2021 Grant (&amp;ldquo;Towards a smart platform for remote diabetic retinopathy screening: quality control in fundus photographs using autoencoders&amp;rdquo;). Convocatoria Jóvenes Investigadores JOVIN  2020/2021 (Programa de Fortalecimiento a la Ciencia y la Tecnología en Universidades Nacionales, Secretaría de Ciencia, Arte y Tecnología, UNICEN).&lt;/li&gt;
&lt;li&gt;INI 2020 Scholarship (&amp;ldquo;Deep learning algorithms for computer assisted diagnostic of diabetic retino-pathy from fundus photographs&amp;rdquo;). Convocatoria Beca INI de Ingreso a la Investigación (Programa de Fortalecimiento a la Ciencia y la Tecnología en las Universidades Nacionales). Becario: Tomás Castilla.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This project was also awarded with U$D 10.000 in AWS credits after winning the Voted Best by the Audience prize at &lt;a href=&#34;https://www.prendete.com.ar/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Concurso Prendete&lt;/a&gt; (Tandil, Argentina).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Towards a better understanding of glaucoma through fundus photography</title>
      <link>https://ignaciorlando.github.io/project/canoa/</link>
      <pubDate>Fri, 01 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/project/canoa/</guid>
      <description>&lt;p&gt;Glaucoma is one of the leading causes of preventable blindness. Known as &amp;ldquo;the silent thief of sight&amp;rdquo;, it is asymptomatic until it produces a permanent and irreversible damage of the retinal nerve fiber layer. A gold standard imaging technique to identify the disease is still missing: currently, glaucoma is diagnosed using multiple studies, including microperimetry, optical coherence tomography and color fundus phography. As a consequence, detecting it at an early stage through screening campaigns is still prohibitive.&lt;/p&gt;
&lt;p&gt;In this project we aim to improve the usage of color fundus photography in the context of glaucoma screening. To this end, our purpose is to introduce novel deep learning based approaches to discover novel biomarkers on these images. By means of our techniques, clinicians will be able to diagnose glaucoma with higher sensitivity and specificity using this low-cost imaging technique.&lt;/p&gt;
&lt;p&gt;PI: José Ignacio Orlando, PhD&lt;/p&gt;
&lt;p&gt;Collaborators:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mercedes Leguía, MD - Hospital de Alta Complejidad El Cruce Dr. Néstor Carlos Kirchner, Florencio Varela, PBA, Argentina.&lt;/li&gt;
&lt;li&gt;Ignacio Larrabide, PhD - CONICET / PLADEMA-UNICEN, Tandil, Argentina.&lt;/li&gt;
&lt;li&gt;Emmanuel Iarussi, PhD - CONICET / UTN-FRBA, CABA, Argentina.&lt;/li&gt;
&lt;li&gt;Carlos A. Bulant, PhD - CONICET / PLADEMA-UNICEN, Tandil, Argentina.&lt;/li&gt;
&lt;li&gt;Karel van Keer, MD PhD - UZ Leuven, Leuven, Belgium.&lt;/li&gt;
&lt;li&gt;João Barbosa Breda, MD PhD - University of Porto, Porto, Portugal; KU Leuven, Leuven, Belgium.&lt;/li&gt;
&lt;li&gt;Lautaro Gramuglia, Undergraduate student - Facultad de Ciencias Exactas, UNICEN.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Supported by:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PICT 2019-00070 (&amp;ldquo;CANOA: CAracterización morfológica de la cabeza del Nervio Óptico en fotografías de fondo de ojo mediante Aprendizaje profundo&amp;rdquo;). Proyectos de Investigación Científica y Tecnológica PICT 2019 Joven Investigador (FONCyT, Agencia I+D+i, Ministerio de Ciencia, Tecnología e Innovación).&lt;/li&gt;
&lt;li&gt;INI 2020 Scholarship (&amp;ldquo;Artery/vein segmentation in color fundus pictures using deep learning: applications to simulation of retinal hemodynamics&amp;rdquo;). Convocatoria Beca INI de Ingreso a la Investigación (Programa de Fortalecimiento a la Ciencia y la Tecnología en las Universidades Nacionales). Becario: Lautaro Gramuglia.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>On Orthogonal Projections for Dimension Reduction and Applications in Augmented Target Loss Functions for Learning Problems</title>
      <link>https://ignaciorlando.github.io/publication/2019-jmiv-orthogonal/</link>
      <pubDate>Wed, 23 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/publication/2019-jmiv-orthogonal/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Multiclass Segmentation as Multitask Learning for Drusen Segmentation in Retinal Optical Coherence Tomography</title>
      <link>https://ignaciorlando.github.io/publication/2019-miccai-drusen/</link>
      <pubDate>Thu, 10 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/publication/2019-miccai-drusen/</guid>
      <description></description>
    </item>
    
    <item>
      <title>An Amplified-Target Loss Approach for Photoreceptor Layer Segmentation in Pathological OCT Scans</title>
      <link>https://ignaciorlando.github.io/publication/2019-omia-photoreceptors/</link>
      <pubDate>Tue, 08 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/publication/2019-omia-photoreceptors/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Foveal Avascular Zone Segmentation in Clinical Routine Fluorescein Angiographies Using Multitask Learning</title>
      <link>https://ignaciorlando.github.io/publication/2019-omia-faz/</link>
      <pubDate>Tue, 08 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/publication/2019-omia-faz/</guid>
      <description></description>
    </item>
    
    <item>
      <title>REFUGE challenge: A unified framework for evaluating automated methods for glaucoma assessment from fundus photographs</title>
      <link>https://ignaciorlando.github.io/publication/2019-media-refuge/</link>
      <pubDate>Tue, 08 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/publication/2019-media-refuge/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Convocatoria para Estudiantes Avanzados de Ingeniería - EVC-CIN 2019</title>
      <link>https://ignaciorlando.github.io/post/2019-open-position-cin/</link>
      <pubDate>Tue, 03 Sep 2019 12:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/post/2019-open-position-cin/</guid>
      <description>&lt;h2 id=&#34;resumen&#34;&gt;Resumen&lt;/h2&gt;
&lt;p&gt;Estamos entrevistando estudiantes avanzados de Ingeniería de Sistemas para aplicar a las &lt;a href=&#34;http://evc.cin.edu.ar/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Becas de Estímulo a las Vocaciones Científicas (EVC) del Consejo Universitario Nacional (CIN)&lt;/a&gt;. Estas becas te permiten trabajar 12 horas semanales durante 12 meses en un proyecto de investigación específico, con la ayuda de un/a director/a. Los resultados de tu trabajo podés usarlos después como tesis de grado, o como un punto de apoyo para más adelante hacer un postgrado.&lt;/p&gt;
&lt;p&gt;Dado que estas becas son muy competitivas (se dan unas 1500 para todo el país), estamos haciendo una preselección de candidatos, para asegurarnos que el/la postulante que se presente tenga muchas más chances de quedar.&lt;/p&gt;
&lt;p&gt;El proyecto en el que trabajarías si saliera la beca se enfoca en desarrollar métodos basados en deep learning (aprendizaje profundo) para la caracterización de los vasos sanguíneos de la retina, usando como entrada fotografías de fondo de ojo. Queremos poder tener un algoritmo preciso que pueda segmentar el árbol vascular y clasificar cada uno de sus segmentos en arteria o vena.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Si el proyecto te interesa y te entusiasma hacer investigación en un área como esta, mandame &lt;strong&gt;antes del 1ero de octubre de 2019&lt;/strong&gt; un mail con el asunto &amp;ldquo;EVC-CIN 2019&amp;rdquo; y tu CV como adjunto a &lt;a href=&#34;mailto:jiorlando@conicet.gov.ar&#34;&gt;jiorlando@conicet.gov.ar&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Más abajo vas a encontrar más detalles sobre la convocatoria, el proyecto y el grupo de investigación.&lt;/p&gt;
&lt;p&gt;Mucha suerte!&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;requisitos-mínimos-preselección-y-fechas&#34;&gt;Requisitos mínimos, preselección y fechas&lt;/h2&gt;
&lt;p&gt;Los requisitos mínimos de la convocatoria podés encontrarlos &lt;a href=&#34;http://evc.cin.edu.ar/attachments/article/11/B-%20REGLAMENTO%20BECAS%20EVC%202019.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;en este link&lt;/a&gt;. En resumen, necesitás:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;No ser mayor de 30 años al 31 de diciembre de 2019.&lt;/li&gt;
&lt;li&gt;Tener un promedio con aplazos mayor a 6 puntos.&lt;/li&gt;
&lt;li&gt;Tener aprobados con finales más del 50% de las materias de la carrera (tené en cuenta que esto también incluye a las optativas).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Si además tenés algo de experiencia programando en Python o algunas ideas básicas de machine learning o deep learning, es un plus más para nosotros, aunque no es excluyente. Sí nos parece importante que el/la candidato/a sea alguien proactivo/a y que lo/a entusiasme mucho la investigación.&lt;/p&gt;
&lt;p&gt;Aunque la convocatoria en sí no exige una preselección, analizaremos los perfiles de todos/as los/as candidatos/as que se postulen para asegurarnos que la persona seleccionada tenga muchas chances de quedar.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;La fecha límite para participar de la preselección es el &lt;strong&gt;1ero de octubre de 2019&lt;/strong&gt;. Cumplido ese plazo, tenemos tiempo hasta el &lt;strong&gt;4 de octubre de 2019&lt;/strong&gt; para presentar toda la documentación y presentarnos a la beca.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Por fechas de resultados y más, &lt;a href=&#34;http://evc.cin.edu.ar/attachments/article/11/cronograma%20evc%202019.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;consultá el calendario oficial&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;el-proyecto&#34;&gt;El proyecto&lt;/h2&gt;
&lt;p&gt;Muchas enfermedades tanto visuales como sistémicas se manifiestan a través de alteraciones en la distribución o morfología del árbol vascular de la retina. Las &lt;a href=&#34;https://en.wikipedia.org/wiki/Fundus_photography&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;fotografías de fondo de ojo&lt;/a&gt; son una modalidad de imagen médica que permite estudiar de manera no-invasiva la retina y sus diferentes regiones anatómicas, incluyendo los vasos sanguíneos.&lt;/p&gt;
&lt;p&gt;La idea central del proyecto es utilizar &lt;a href=&#34;https://en.wikipedia.org/wiki/Convolutional_neural_network&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;redes neuronales convolucionales (convolutional neural networks)&lt;/a&gt; para procesar fotografías de fondo de ojo y extraer información de interés sobre la morfología vascular. En particular, queremos poder desarrollar un método lo suficientemente robusto como para simultaneamente &lt;a href=&#34;https://ieeexplore.ieee.org/document/7420682&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;segmentar&lt;/a&gt; y &lt;a href=&#34;https://limo.libis.be/primo-explore/fulldisplay?docid=LIRIAS2811989&amp;amp;context=L&amp;amp;vid=Lirias&amp;amp;search_scope=Lirias&amp;amp;tab=default_tab&amp;amp;lang=en_US&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;clasificar&lt;/a&gt; cada uno de los vasos sanguíneos en arteria o vena. Contar con esta herramienta nos permitirá más adelante estudiar de forma mucho más eficiente grandes volúmenes de imágenes, y poder realizar &lt;a href=&#34;https://arxiv.org/pdf/1805.10273.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;simulaciones hemodinámicas&lt;/a&gt; para comprender si ciertos parámetros obtenidos de dichas simulaciones se relacionan o no con la presencia de algunas enfermedades.&lt;/p&gt;
&lt;p&gt;El proyecto estará supervisado por mí. Durante el transcurso de la beca vamos a utilizar el lenguaje de programación Python y la librería para deep learning Pytorch para desarrollar los métodos propuestos, además de placas gráficas de NVIDIA para correr los experimentos. Además, la iniciativa involucra aprender conceptos muy interesantes de análisis de imagen, visión computacional y machine learning, y embarrarnos un toque con una matemática no muy áspera :)&lt;/p&gt;
&lt;p&gt;Si querés saber más, mandame un mail a &lt;a href=&#34;mailto:jiorlando@conicet.gov.ar&#34;&gt;jiorlando@conicet.gov.ar&lt;/a&gt; y nos juntamos a conversar un poco más del tema. También podés encontrar más información sobre temas relacionados en algunas de nuestras publicaciones más recientes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Orlando, J. I., Breda, J. B., Van Keer, K., Blaschko, M. B., Blanco, P. J., &amp;amp; Bulant, C. A. (2018, September). &lt;a href=&#34;https://arxiv.org/abs/1805.10273&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Towards a glaucoma risk index based on simulated hemodynamics from fundus images&lt;/a&gt;. In International Conference on Medical Image Computing and Computer-Assisted Intervention (pp. 65-73). Springer, Cham.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Orlando, J. I., Prokofyeva, E., del Fresno, M., &amp;amp; Blaschko, M. B. (2018). &lt;a href=&#34;https://arxiv.org/abs/1706.03008&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;An ensemble deep learning based approach for red lesion detection in fundus images&lt;/a&gt;. Computer methods and programs in biomedicine, 153, 115-127.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Orlando, J. I., Van Keer, K., Barbosa Breda, J., Manterola, H. L., Blaschko, M. B., &amp;amp; Clausse, A. (2017). &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pubmed/29044550&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Proliferative diabetic retinopathy characterization based on fractal features: Evaluation on a publicly available dataset&lt;/a&gt;. Medical physics, 44(12), 6425-6434.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Orlando, J. I., Prokofyeva, E., &amp;amp; Blaschko, M. B. (2016). &lt;a href=&#34;https://ieeexplore.ieee.org/document/7420682&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;A discriminatively trained fully connected conditional random field model for blood vessel segmentation in fundus images&lt;/a&gt;. IEEE transactions on Biomedical Engineering, 64(1), 16-27.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;pladema&#34;&gt;PLADEMA&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://www.pladema.net/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PLADEMA&lt;/a&gt; es un instituto de investigación de referencia a nivel nacional en materia de análisis de imagen médica. Ubicados en el Campus Universitario de la UNICEN, contamos con numerosos investigadores responsables distribuidos en varios grupos de investigación que se enfocan en diversas áreas, yendo desde la computación gráfica y la simulación hasta el análisis de redes de energía y sistemas de transporte.&lt;/p&gt;
&lt;p&gt;Como parte de este proyecto te incorporarías a Yatiris, el grupo de análisis de imágenes médicas. Además de un excelente clima de laburo y unos muy buenos cebadores de mates, contamos con acceso a recursos de cómputo suficientes para que puedas trabajar sin inconvenientes y hacer los experimentos necesarios. Contamos además con acceso a bases de datos públicas de imágenes de la retina, y contacto con instituciones de salud en Argentina, Bélgica y Austria como para acceder a datos extra de ser necesario. Como tu potencial director, te puedo ofrecer toda la mano que necesites (incluso codeando! amo codear, jeje) y algunos años de experiencia ya laburando con este tipo de imágenes.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>I got a permanent position as an Assistant Researcher at CONICET, Argentina</title>
      <link>https://ignaciorlando.github.io/post/2019-09-01-conicet/</link>
      <pubDate>Sun, 01 Sep 2019 12:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/post/2019-09-01-conicet/</guid>
      <description>&lt;p&gt;In September 13th I&amp;rsquo;ll be landing in Argentina to be once again part of PLADEMA, this time as an Assistant Researcher funded by CONICET.
I&amp;rsquo;ll be joining again Yatiris, a group within PLADEMA developing cutting edge technologies for medical image analysis using computer vision, machine learning and
pattern recognition techniques. I&amp;rsquo;ll be responsible of coordinating all the deep learning initiatives, while continuing my own line of research in computer-assisted
ophthalmology.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s hard to say goodbye to OPTIMA and such an amazing group of talents and good people. My time in Vienna was so exciting, full of research
projects from which I learned a lot.
I would like to thank Prof. Schmidt-Erfurth for trusting in me for this position, and also to Bianca Gerendas, Hrvoje Bogunović, Sebastian Waldstein
and Martin Ehler for their continuous support. I would also like to thank all of my colleagues in the lab, specially Philipp, Dominik, Antoine,
Wolf, Rhona, David, Thomas and Sophie. Some of them have turned into really good friends of mine that I will miss a lot being abroad!&lt;/p&gt;
&lt;p&gt;That being said, I&amp;rsquo;m glad to move back to Argentina to give back to the country at least a little bit in proportion to what it did to me since I was born there :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Improving realism in patient-specific abdominal ultrasound simulation using CycleGANs</title>
      <link>https://ignaciorlando.github.io/publication/2019-ijcars-us/</link>
      <pubDate>Wed, 07 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/publication/2019-ijcars-us/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Two papers accepted for OMIA 2019!</title>
      <link>https://ignaciorlando.github.io/post/2019-08-01-omia/</link>
      <pubDate>Tue, 30 Jul 2019 12:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/post/2019-08-01-omia/</guid>
      <description>&lt;p&gt;We got two papers accepted for publication at the OMIA workshop in MICCAI 2019 in Shengzen, China.&lt;/p&gt;
&lt;p&gt;In &amp;ldquo;An amplified-target loss approach for photoreceptor layer segmentation in pathological OCT scans&amp;rdquo;, Anna Breger and I introduced an approach to increase penalization of errors in the central area of the input B-scan. By means of this approach, we force the neural network to take more into account the abnormalities that appear in the center of the scans in pathological retinas, improving results in photoreceptor layer segmentation. My other co-authors are Hrvoje Bogunović, Sophie Riedl, Bianca S. Gerendas, Martin Ehler and Ursula Schmidt-Erfurth.&lt;/p&gt;
&lt;p&gt;In &amp;ldquo;Foveal Avascular Zone Segmentation in Clinical Routine Fluorescein Angiographies Using Multitask Learning&amp;rdquo;, Dominik Hofer introduces a multitask learning approach for FAZ segmentation in FA images. To the classical segmentation branch, we add a second decoder that outputs an Euclidean distance map. By penalizing errors both in segmentation and in this regression map, we increase the regularization of the model and improve its results in clinical routine images. The other co-authors are Philipp Seeböck, Georgios Mylonas, Felix Goldbach, Amir Sadeghipour, Bianca S Gerendas, Ursula Schmidt-Erfurth. This is part of Dominik&amp;rsquo;s PhD thesis, supervised by Bianca S Gerendas and Philipp Seeböck.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>U2-Net: A Bayesian U-Net model with epistemic uncertainty feedback for photoreceptor layer segmentation in pathological OCT scans</title>
      <link>https://ignaciorlando.github.io/publication/2019-isbi-photoreceptors/</link>
      <pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/publication/2019-isbi-photoreceptors/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Using CycleGANs for effectively reducing image variability across OCT devices and improving retinal fluid segmentation</title>
      <link>https://ignaciorlando.github.io/publication/2019-isbi-cyclegan/</link>
      <pubDate>Thu, 11 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/publication/2019-isbi-cyclegan/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Linking Function and Structure: Prediction of Retinal Sensitivity in AMD from OCT using Deep Learning</title>
      <link>https://ignaciorlando.github.io/publication/2019-arvo-microperimetry/</link>
      <pubDate>Mon, 01 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/publication/2019-arvo-microperimetry/</guid>
      <description></description>
    </item>
    
    <item>
      <title>New paper at MICCAI 2019!</title>
      <link>https://ignaciorlando.github.io/post/2019-06-05-miccai/</link>
      <pubDate>Wed, 05 Jun 2019 12:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/post/2019-06-05-miccai/</guid>
      <description>&lt;p&gt;Our paper entitled &amp;ldquo;Multiclass segmentation as multitask learning for drusen segmentation in retinal optical coherence tomography&amp;rdquo; has been accepted for publication at MICCAI 2019!&lt;/p&gt;
&lt;p&gt;Drusen segmentation in OCT is a challenging task. In general, it is posed either as a binary segmentation problem (drusen vs. everything else) or as a layer segmentation problem (by detecting the outer boundary of the RPE and the Bruch&amp;rsquo;s membrane). Each approach has its advantages and disadvantages: binary segmentation might be prone to false positives in areas that are not anatomically plausible, while layer segmentation might fail under the presence of large drusenoid deposits. In this paper we propose to take the best of each world by posing a multiclass segmentation problem in which we target both layers and drusen. Furthermore, instead of training a single, large capacity U-Net model with a multiclass cross entropy loss, we propose to benefit from multitask learning. To this end, we disentangle the multiclass problem as a series of binary segmentation tasks, and we assign to each of them its own decoder, while sharing a single encoder through skip connections. We also analyze if adding connections between the decoders for the layers with the decoder of the drusen segmentation task helps or not. In our experiments we observed better performance when no gradient flow is allowed through these extra connections.&lt;/p&gt;
&lt;p&gt;If you have other problems with &amp;ldquo;sandwiched&amp;rdquo; classes, then maybe this idea can help you to boost your performance :)&lt;/p&gt;
&lt;p&gt;This paper is part of Rhona Asgari&amp;rsquo;s PhD thesis, supervised by Hrvoje Bogunović at OPTIMA.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Exploiting Epistemic Uncertainty of Anatomy Segmentation for Anomaly Detection in Retinal OCT</title>
      <link>https://ignaciorlando.github.io/publication/2019-tmi-anomaly/</link>
      <pubDate>Fri, 31 May 2019 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/publication/2019-tmi-anomaly/</guid>
      <description></description>
    </item>
    
    <item>
      <title>U2-Net: A Bayesian U-Net Model with Epistemic Uncertainty Feedback for Photoreceptor Layer Segmentation in Pathological OCT Scans</title>
      <link>https://ignaciorlando.github.io/talk/u2-net-a-bayesian-u-net-model-with-epistemic-uncertainty-feedback-for-photoreceptor-layer-segmentation-in-pathological-oct-scans/</link>
      <pubDate>Wed, 10 Apr 2019 15:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/talk/u2-net-a-bayesian-u-net-model-with-epistemic-uncertainty-feedback-for-photoreceptor-layer-segmentation-in-pathological-oct-scans/</guid>
      <description></description>
    </item>
    
    <item>
      <title>New paper at IJCARS 2019!</title>
      <link>https://ignaciorlando.github.io/post/2019-07-30-ijcars/</link>
      <pubDate>Tue, 05 Feb 2019 12:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/post/2019-07-30-ijcars/</guid>
      <description>&lt;p&gt;Our paper entitled &amp;ldquo;Improving realism in patient specific Ultrasound simulation using CycleGANs&amp;rdquo; has been accepted for publication in the International Journal of Computer Assisted Radiology and Surgery (IJCARS)! This is an extension of what Santiago presented at CARS 2019 in Rennes, France.&lt;/p&gt;
&lt;p&gt;In this article we present a hybrid approach towards US simulation that combines ray-casting techniques with CycleGANs. The key idea is to use these generative models to alleviate the drawback of current available simulation techniques. In particular, traditional ray-casting based solutions for US simulation usually fail to model complex features such as artifacts or attenuations that are typical from this imaging modality. To overcome this difficulty, we propose to train a CycleGAN using unpaired real US scans and ray-casting based simulations. The model is then applied on simulated images to get more realistic representations. We experimentally evaluated our approach in a user study with a cohort of more than 20 participants, observing that a ResNet based generator is able to significantly improved the appeareance of the images.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;We will need more US experts to further validate our approach&lt;/em&gt;, so if you are willing to help us please contact Santiago Vitale as &lt;a href=&#34;mailto:svitale@conicet.gov.ar&#34;&gt;svitale@conicet.gov.ar&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This work was part of a collaboration with Santiago Vitale and Ignacio Larrabide, from Pladema / CONICET, and Emmanuel Iarussi, from UTN and also from CONICET. This is also part of Santiago&amp;rsquo;s PhD thesis on abdominal ultrasound simulation.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Poster presentation at CARS 2019!</title>
      <link>https://ignaciorlando.github.io/post/2019-05-02-cars/</link>
      <pubDate>Tue, 05 Feb 2019 12:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/post/2019-05-02-cars/</guid>
      <description>&lt;p&gt;Our paper entitled &amp;ldquo;Improving realism in patient specific Ultrasound simulation using CycleGANs&amp;rdquo; has been accepted for poster presentation at CARS 2019 in Rennes, France.&lt;/p&gt;
&lt;p&gt;This work was part of a collaboration with Santiago Vitale and Ignacio Larrabide, from Pladema / CONICET, and Emmanuel Iarussi, from UTN and also from CONICET.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>https://ignaciorlando.github.io/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-wowchemy&#34;&gt;Create slides in Markdown with Wowchemy&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wowchemy&lt;/a&gt; | &lt;a href=&#34;https://owchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
    print(&amp;quot;Eating...&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;fragment &#34; &gt;
One
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
&lt;strong&gt;Two&lt;/strong&gt;
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
Three
&lt;/span&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; slide background-image=&amp;quot;/media/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.reveal section h1,
.reveal section h2,
.reveal section h3 {
  color: navy;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wowchemy/wowchemy-hugo-modules/discussions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Two papers accepted for ISBI 2019!</title>
      <link>https://ignaciorlando.github.io/post/2018-12-18-isbi/</link>
      <pubDate>Tue, 18 Dec 2018 12:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/post/2018-12-18-isbi/</guid>
      <description>&lt;p&gt;Excellent news to finish an amazing year of work at &lt;a href=&#34;https://optima.meduniwien.ac.at&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OPTIMA&lt;/a&gt;! We got two papers accepted for presentation at ISBI 2019 :)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&amp;ldquo;U2-Net: A Bayesian U-Net model with epistemic uncertainty feedback for photoreceptor layer segmentation in pathological OCT scans&amp;rdquo;&lt;/strong&gt; describes a novel U-shaped architecture for photoreceptor layer segmentation in OCT scans. We modified the basic U-Net with LeakyReLUs, batch normalization and dropout to improve the original segmentation performance. Additionally, we used epistemic uncertainty estimation based on Monte Carlo sampling with dropout on test time to provide qualitative feedback about potential errors of the network. We compared our performance with other baseline approaches and we got state of the art performance for this segmentation task! This study was possible thanks to the support of my co-authors: &lt;a href=&#34;https://optima.meduniwien.ac.at/about-us/team/computational-imaging-research/philipp-seeboeck/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Phillip Seeböck&lt;/a&gt; and &lt;a href=&#34;https://optima.meduniwien.ac.at/about-us/team/computational-imaging-research/hrvoje-bogunovic/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hrvoje Bogunović&lt;/a&gt; (who helped me with the technical details), &lt;a href=&#34;https://optima.meduniwien.ac.at/about-us/team/clinical-research/sophie-klimscha/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sophie Klimscha&lt;/a&gt; and &lt;a href=&#34;https://optima.meduniwien.ac.at/about-us/team/clinical-research/christoph-grechenig/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Christoph Grechenig&lt;/a&gt; (who coordinated the manual annotation procedure for us, thank you guys!), and &lt;a href=&#34;https://optima.meduniwien.ac.at/about-us/team/clinical-research/sebastian-waldstein/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sebastian Waldstein&lt;/a&gt;, &lt;a href=&#34;https://optima.meduniwien.ac.at/about-us/team/clinical-research/bianca-s-gerendas/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Bianca S. Gerendas&lt;/a&gt; and &lt;a href=&#34;https://optima.meduniwien.ac.at/about-us/team/clinical-research/ursula-schmidt-erfurth/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ursula Schmidt-Erfurth&lt;/a&gt; (who supervised the study). Thanks a lot!&lt;/p&gt;
&lt;p&gt;The second papers is &lt;strong&gt;&amp;ldquo;Using CycleGANs for effectively reducing image variability across OCT devices and improving retinal fluid segmentation&amp;rdquo;&lt;/strong&gt;, and it is a joint research lead both by &lt;a href=&#34;https://optima.meduniwien.ac.at/about-us/team/computational-imaging-research/philipp-seeboeck/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Phillip Seeböck&lt;/a&gt; and &lt;a href=&#34;https://optima.meduniwien.ac.at/about-us/team/computational-imaging-research/david-romo-bucheli/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;David Romo-Bucheli&lt;/a&gt;. They introduced the idea of using a CycleGAN to reduce the covariate shift between different OCT devices and allows the transfer of existing segmentation models. I&amp;rsquo;ve colaborated with them developing part of the segmentation model. The other co-authors are &lt;a href=&#34;https://optima.meduniwien.ac.at/about-us/team/clinical-research/sebastian-waldstein/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sebastian Waldstein&lt;/a&gt;, &lt;a href=&#34;https://optima.meduniwien.ac.at/about-us/team/computational-imaging-research/hrvoje-bogunovic/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hrvoje Bogunović&lt;/a&gt;, &lt;a href=&#34;https://optima.meduniwien.ac.at/about-us/team/clinical-research/bianca-s-gerendas/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Bianca S. Gerendas&lt;/a&gt;, &lt;a href=&#34;https://optima.meduniwien.ac.at/about-us/team/computational-imaging-research/georg-langs/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Georg Langs&lt;/a&gt; and &lt;a href=&#34;https://optima.meduniwien.ac.at/about-us/team/clinical-research/ursula-schmidt-erfurth/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ursula Schmidt-Erfurth&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We kindly acknowledge the funding agencies supporting this research, including the Christian Doppler Research Association, the Austrian Federal Ministry for Digital and Economic Affairs and the National Foundation for Research, Technology and Development and the Austrian Science Fund, towards the projects FWF I2714-B31 and WWTF AugUniWien / FA746A0249. We also thank the NVIDIA Corporation for donating Titan X and Titan XP GPUs for our experiments.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Machine learning for ophthalmic image analysis</title>
      <link>https://ignaciorlando.github.io/talk/machine-learning-for-ophthalmic-image-analysis/</link>
      <pubDate>Fri, 07 Dec 2018 15:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/talk/machine-learning-for-ophthalmic-image-analysis/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Retinal imaging talk at FCEN / UBA (Argentina)</title>
      <link>https://ignaciorlando.github.io/post/2018-12-07-uba-presentation/</link>
      <pubDate>Fri, 07 Dec 2018 12:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/post/2018-12-07-uba-presentation/</guid>
      <description>&lt;p&gt;In December 7th I gave a lecture on machine learning for ophthalmic image analysis to the students of the &amp;ldquo;Deep Learning for Medical Image Analysis&amp;rdquo; course that &lt;a href=&#34;https://eferrante.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Enzo Ferrante&lt;/a&gt; taught at the Computer Science Department from Facultad de Ciencias Exactas y Naturales, UBA. Thanks Enzo for the invitation!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Towards a Glaucoma Risk Index Based on Simulated Hemodynamics from Fundus Images</title>
      <link>https://ignaciorlando.github.io/publication/2018-miccai-hemodynamics/</link>
      <pubDate>Wed, 26 Sep 2018 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/publication/2018-miccai-hemodynamics/</guid>
      <description></description>
    </item>
    
    <item>
      <title>REFUGE: Retinal Fundus Glaucoma Challenge</title>
      <link>https://ignaciorlando.github.io/post/2018-07-24-refuge/</link>
      <pubDate>Tue, 24 Jul 2018 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/post/2018-07-24-refuge/</guid>
      <description>&lt;p&gt;This year I&amp;rsquo;ll be joining Yanwu Xu (Frank), Huazhu Fu and Hrvoje Bogunović as a co-organizer of &lt;a href=&#34;https://refuge.grand-challenge.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;REFUGE&lt;/a&gt;, the first MICCAI challenge on glaucoma detection in fundus images! It will be held as part of the &lt;a href=&#34;https://sites.google.com/site/mwomia2018/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ophthalmic Medical Image Analysis (OMIA) workshop&lt;/a&gt; at &lt;a href=&#34;https://www.miccai2018.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MICCAI 2018&lt;/a&gt; in Granada (Spain).&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ll be responsible of grading the teams based on their submitted results, presenting the outcomes of the challenge and writing the summary publication. Thanks Hrvoje and Frank for your vote of confidence!&lt;/p&gt;
&lt;p&gt;The deadline for submitting results on the REFUGE validation set either for glaucoma detection, optic disc/cup segmentation and/or fovea detection is this Friday 28th! Looking forward for your submissions!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>New paper at MICCAI 2018!</title>
      <link>https://ignaciorlando.github.io/post/2018-05-25-miccai/</link>
      <pubDate>Fri, 25 May 2018 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/post/2018-05-25-miccai/</guid>
      <description>&lt;p&gt;Our paper entitled &amp;ldquo;Towards a glaucoma risk index based on simulated hemodynamics from fundus images&amp;rdquo; has been accepted for presentation in MICCAI 2018!&lt;/p&gt;
&lt;p&gt;In this article we present one of the first attempts to characterize the hemodynamics of the retinal arterioles on glaucomatous patients. We have used a 0D model for simulating the blood flow in patient specific segmentations of the arteries, and proposed a novel dictionary-learning based strategy for summarizing all the hemodynamic outcomes into a fixed length feature vector. By means of this approach we want to perform clinical studies on large populations to understand the hemodynamics of glaucomatous patients!&lt;/p&gt;
&lt;p&gt;We have good news for you, btw! Jointly with the manuscript, we will also release our code&amp;hellip; and data! We have built LES-AV, a set of 22 fundus photographs taken from the Leuven Eye Study. The images include not only manual annotations of the retinal vessels, but also their classification into arteries and veins.&lt;/p&gt;
&lt;p&gt;This work was part of a collaboration with João Barbosa Breda, Karel van Keer, Matthew B. Blaschko, Pablo J. Blanco and Carlos A. Bulant. This is also part of the work that I made after defending my thesis in Argentina, and before moving to Vienna to join OPTIMA. So, yeah, it is cool to see CONICET again in the MICCAI proceedings :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>I got an NVIDIA Hardware Grant</title>
      <link>https://ignaciorlando.github.io/post/2018-02-14-nvidia/</link>
      <pubDate>Wed, 14 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/post/2018-02-14-nvidia/</guid>
      <description>&lt;p&gt;My application to the &lt;a href=&#34;https://developer.nvidia.com/academic_gpu_seeding&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NVIDIA Hardware Grant&lt;/a&gt; was succesful! As part of this grant, I will receive a &lt;a href=&#34;https://www.nvidia.com/en-us/titan/titan-xp/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NVIDIA Titan XP GPU&lt;/a&gt; to perform my research on deep learning techniques for OCT image analysis. I thank NVIDIA Corporation for providing me with this cutting-edge hardware that will certainly help me to improve the efficiency of my methods.&lt;/p&gt;
&lt;p&gt;Update 2028-03-15: I got the Titan Xp and I&amp;rsquo;m ready to put it on my computer!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Moving to Vienna!</title>
      <link>https://ignaciorlando.github.io/post/2018-01-08-optima/</link>
      <pubDate>Mon, 08 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/post/2018-01-08-optima/</guid>
      <description>&lt;p&gt;I&amp;rsquo;m glad to tell you, guys, that since next week I will be formally part of the &lt;a href=&#34;https://optima.meduniwien.ac.at/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Christian Doppler Laboratory for Ophthalmic Image Analysis (OPTIMA)&lt;/a&gt;, a multidisciplinary research team that belongs to the Department of Ophthalmology and Optometry of the Medical University of Vienna (Austria). I&amp;rsquo;m joining the laboratory as a Postdoctoral Research Associate, working on automated OCT image analysis using deep learning techniques. My research will be funded by the project WWTF AugUniWien / FA746A0249. I&amp;rsquo;m really looking forward to start to work with this amazing team!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An ensemble deep learning based approach for red lesion detection in fundus images</title>
      <link>https://ignaciorlando.github.io/publication/2018-cmpb-lesion/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/publication/2018-cmpb-lesion/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Retinal blood vessel segmentation in high resolution fundus photographs using automated feature parameter estimation</title>
      <link>https://ignaciorlando.github.io/publication/2017-sipaim-vessels/</link>
      <pubDate>Fri, 17 Nov 2017 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/publication/2017-sipaim-vessels/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Proliferative diabetic retinopathy characterization based on fractal features: Evaluation on a publicly available dataset</title>
      <link>https://ignaciorlando.github.io/publication/2017-medphys-fractal/</link>
      <pubDate>Mon, 06 Nov 2017 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/publication/2017-medphys-fractal/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Retinal blood vessel segmentation in high resolution fundus photographs using automated parameter estimation</title>
      <link>https://ignaciorlando.github.io/talk/retinal-blood-vessel-segmentation-in-high-resolution-fundus-photographs-using-automated-parameter-estimation/</link>
      <pubDate>Fri, 06 Oct 2017 15:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/talk/retinal-blood-vessel-segmentation-in-high-resolution-fundus-photographs-using-automated-parameter-estimation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Aprendizaje automático para asistencia al diagnóstico de enfermedades visuales basado en imágenes de fondo de ojo (Machine learning for ophthalmic screening and diagnostics from fundus images)</title>
      <link>https://ignaciorlando.github.io/publication/2017-thesis-retina/</link>
      <pubDate>Thu, 21 Sep 2017 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/publication/2017-thesis-retina/</guid>
      <description></description>
    </item>
    
    <item>
      <title>I&#39;ve defended my PhD thesis!</title>
      <link>https://ignaciorlando.github.io/post/2017-09-22-phd-defense/</link>
      <pubDate>Tue, 12 Sep 2017 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/post/2017-09-22-phd-defense/</guid>
      <description>&lt;p&gt;Yesterday, September 21th 2017, I have officially defended my PhD thesis!! It was quite an intense day. The night before there was a huge storm that broke several windows in the university. As a result, the Rector decided to cancel the activities&amp;hellip; of course including my defense. And, even worse, one of the members of the jury had to leave right after my defense, so under no circunstance it was possible to move it to a different day. Luckily for me, Mariana del Fresno, my PhD advisor, managed to move all the planets so that I can defend on ADUNCE&amp;rsquo;s room at the university rectorate. Yes, I defended my thesis in a union, isn&amp;rsquo;t that great?&lt;/p&gt;
&lt;p&gt;My thesis is entitled &amp;ldquo;Machine learning for ophthalmic screening and diagnostics from fundus images&amp;rdquo;. You can find its English version &lt;a href=&#34;https://lirias.kuleuven.be/bitstream/123456789/592162/1/tesis.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;, and the Spanish version &lt;a href=&#34;http://www.ridaa.unicen.edu.ar/xmlui/handle/123456789/1476&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;. Yes, I wrote it twice because by the time I was told that submitting it in English was not allowed, it was already finished.&lt;/p&gt;
&lt;p&gt;Most of the code of each of the contributions is available on my github profile. Feel free to clone the repositories and experiment with them!&lt;/p&gt;
&lt;p&gt;I would like to thank my supervisors, Matthew and Mariana, for guiding me through all this years. I would also like to thank the members of the jury, Prof. Dr. José M. Massa, Prof. Dra. Virginia Ballarin and Prof. Dr. Pablo Granitto, for carefully reading the thesis.&lt;/p&gt;
&lt;p&gt;Now I will continue working as a postdoc at PLADEMA, until 2018, when I&amp;rsquo;m leaving to Vienna to join the Christian Doppler Laboratory for Ophthalmic Image Analysis.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Convolutional neural network transfer for automated glaucoma identification</title>
      <link>https://ignaciorlando.github.io/publication/2017-sipaim-glaucoma/</link>
      <pubDate>Thu, 26 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/publication/2017-sipaim-glaucoma/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Convolutional Neural Network Transfer for Automated Glaucoma Identification</title>
      <link>https://ignaciorlando.github.io/talk/convolutional-neural-network-transfer-for-automated-glaucoma-identification/</link>
      <pubDate>Tue, 06 Dec 2016 11:15:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/talk/convolutional-neural-network-transfer-for-automated-glaucoma-identification/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Discriminatively Trained Fully Connected Conditional Random Field Model for Blood Vessel Segmentation in Fundus Images</title>
      <link>https://ignaciorlando.github.io/publication/2016-tbme-vessels/</link>
      <pubDate>Fri, 26 Feb 2016 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/publication/2016-tbme-vessels/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Assessment of image features for vessel wall segmentation in intravascular ultrasound images</title>
      <link>https://ignaciorlando.github.io/publication/2016-ijcars-ivus/</link>
      <pubDate>Mon, 25 Jan 2016 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/publication/2016-ijcars-ivus/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Learning Fully-Connected CRFs for Blood Vessel Segmentation in Retinal Images</title>
      <link>https://ignaciorlando.github.io/publication/2014-miccai-vessels/</link>
      <pubDate>Fri, 10 Oct 2014 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/publication/2014-miccai-vessels/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Arabidopsis Roots Segmentation Based on Morphological Operations and CRFs</title>
      <link>https://ignaciorlando.github.io/publication/2014-ecimag-arabidopsis/</link>
      <pubDate>Fri, 15 Aug 2014 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/publication/2014-ecimag-arabidopsis/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Reviewing Preprocessing and Feature Extraction Techniques for Retinal Blood Vessels Segmentation in Fundus Images</title>
      <link>https://ignaciorlando.github.io/publication/2014-mecom-vessels/</link>
      <pubDate>Mon, 23 Jun 2014 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/publication/2014-mecom-vessels/</guid>
      <description></description>
    </item>
    
    <item>
      <title>My ISBI 2019 was chosen for oral presentation</title>
      <link>https://ignaciorlando.github.io/post/2019-03-24-isbi/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://ignaciorlando.github.io/post/2019-03-24-isbi/</guid>
      <description>&lt;p&gt;Our paper on photoreceptor segmentation in retinal OCT scans was accepted for oral presentation at ISBI 2019. You can read the &lt;a href=&#34;https://arxiv.org/abs/1901.07929&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;preprint or arXiv here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
